{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active learning - part 1 - model inference (sampling)\n",
    "\n",
    "Before running the script, check the `src/config/active_learning.yaml`:\n",
    "1. Modify the `coref_model.model_dir` to the last iter model dir\n",
    "2. Modify the `current_iter` and `sampling_num`\n",
    "\n",
    "Run:\n",
    "1. Run `Step 1: Model Inference and Data Sampling`\n",
    "2. Run `Step 2: Generate brat data for annotation`\n",
    "3. Run `Step 3: Send BRAT data to the BRAT server`\n",
    "4. Run `Step 4: Send notification to annotator via email`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src/\")\n",
    "sys.path.append(\"../../../../git_clone_repos/fast-coref/src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "config = None\n",
    "with initialize(version_base=None, config_path=\"../config\", job_name=\"active_learning\"):\n",
    "    config = compose(config_name=\"active_learning\")\n",
    "# print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Model Inference and Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model: /home/yuxiangliao/PhD/workspace/git_clone_repos/fast-coref/models/coref_model_10_iter11_3/best and doc_encoder: /home/yuxiangliao/PhD/workspace/git_clone_repos/fast-coref/models/longformer_coreference_joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuxiangliao/anaconda3/envs/sr_coref/lib/python3.9/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-06-04 14:53:48,427 - Processing section: findings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c088bf766e41febc4ecce6f8618ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 14:54:34,254 - Processing section: impression\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb18a44b8d3548a8ba87ad4a02408739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "selected index k out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m previous_sampled_doc_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     remove_labeled_data_from_sampling_dict(previous_sampled_doc_dict, extra_info_dict)\n\u001b[0;32m---> 24\u001b[0m curr_sampled_doc_dict \u001b[39m=\u001b[39m sampling_topk_doc_by_MDE(extra_info_dict, sampling_nums, log_dict)\n\u001b[1;32m     25\u001b[0m \u001b[39m#####\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[39m# Save labeled pool info\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(config\u001b[39m.\u001b[39moutput\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mlabeled_pool_info_file, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/PhD/workspace/VSCode_workspace/sr_coref/src/active_learning/../../src/active_learning/sampling.py:82\u001b[0m, in \u001b[0;36msampling_topk_doc_by_MDE\u001b[0;34m(extra_info_dict, sampling_nums, log_dict)\u001b[0m\n\u001b[1;32m     80\u001b[0m doc_highest_entropy_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(doc_highest_entropy_list, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     81\u001b[0m doc_highest_entropy_tensor_nanTo0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnan_to_num(doc_highest_entropy_tensor)\n\u001b[0;32m---> 82\u001b[0m topk_entropy_tensor, topk_indices_tensor \u001b[39m=\u001b[39m doc_highest_entropy_tensor_nanTo0\u001b[39m.\u001b[39;49mtopk(sampling_nums[section_name])\n\u001b[1;32m     84\u001b[0m topk_indices_array \u001b[39m=\u001b[39m topk_indices_tensor\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     85\u001b[0m doc_csv_name_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(doc_csv_name_list)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "from active_learning.sampling import model_inference, sampling_topk_doc_by_MDE, log_runtime_info\n",
    "from active_learning.utils import get_previous_labeled_pool_dict, remove_labeled_data_from_sampling_dict\n",
    "\n",
    "# Average sampling from each section\n",
    "target_sections = [\"findings\", \"impression\"]\n",
    "sampling_nums = {\n",
    "    \"findings\": config.sampling_num - (config.sampling_num // 2),\n",
    "    \"impression\": config.sampling_num // 2,\n",
    "}\n",
    "startTime = time.time()\n",
    "log_dict = defaultdict(dict)\n",
    "\n",
    "#####\n",
    "# Here's the main functions\n",
    "extra_info_dict = model_inference(config, target_sections, log_dict)\n",
    "\n",
    "## Remove previous sampled doc records from `extra_info_dict`\n",
    "previous_sampled_doc_dict = get_previous_labeled_pool_dict(config)\n",
    "if previous_sampled_doc_dict is not None:\n",
    "    remove_labeled_data_from_sampling_dict(previous_sampled_doc_dict, extra_info_dict)\n",
    "\n",
    "curr_sampled_doc_dict = sampling_topk_doc_by_MDE(extra_info_dict, sampling_nums, log_dict)\n",
    "#####\n",
    "\n",
    "# Save labeled pool info\n",
    "with open(config.output.log.labeled_pool_info_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    if previous_sampled_doc_dict is not None:\n",
    "        for section_name, doc_list in previous_sampled_doc_dict.items():\n",
    "            f.write(\"\\n\".join([f\"{section_name}/{doc_name}\" for doc_name in doc_list]))\n",
    "            f.write(\"\\n\")\n",
    "    for section_name, doc_list in curr_sampled_doc_dict.items():\n",
    "        f.write(\"\\n\".join([f\"{section_name}/{doc_name}\" for doc_name in doc_list]))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "log_out = log_runtime_info(config, log_dict, startTime)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate brat data for annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from active_learning.process_brat_annotation import prepare_brat, copy_brat_configs\n",
    "\n",
    "brat_output_dir = prepare_brat(config, curr_sampled_doc_dict)\n",
    "copy_brat_configs(config.brat_config.base_dir, brat_output_dir)\n",
    "\n",
    "print(\"Data for BRAT annotation has been created to: \\n\", brat_output_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Send BRAT data to the BRAT server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from active_learning.communicate_brat_server import RemoteConnection\n",
    "\n",
    "brat_unfinished_dir = config.output.brat.unfinished_dir\n",
    "brat_server_dir = config.remote_server.brat.data_dir\n",
    "\n",
    "hostname = config.remote_server.brat.hostname\n",
    "username = config.remote_server.brat.username\n",
    "password = config.remote_server.brat.password\n",
    "connection = RemoteConnection(hostname, username, password)\n",
    "connection.put_all(\n",
    "    brat_unfinished_dir,\n",
    "    brat_server_dir,\n",
    ")\n",
    "\n",
    "base_name_old = os.path.basename(brat_unfinished_dir)\n",
    "base_name_new = f\"iter_{config.current_iter}\"\n",
    "connection.rename(os.path.join(brat_server_dir, base_name_old), os.path.join(brat_server_dir, base_name_new))\n",
    "connection.close_client()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Send notification to annotator via email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "\n",
    "def send_mail(to_emails: list, content: str, subject=\"VISA slot available\",\n",
    "              server='smtp.qq.com', from_email='', password=''):\n",
    "\n",
    "    message = MIMEText(content, 'plain', 'utf-8')  # 内容, 格式, 编码\n",
    "    message['From'] = from_email\n",
    "    message['To'] = \",\".join(to_emails)\n",
    "    message['Subject'] = subject\n",
    "\n",
    "    try:\n",
    "        server = smtplib.SMTP_SSL(\"smtp.qq.com\", 465)\n",
    "        server.login(from_email, password)\n",
    "        server.sendmail(from_email, from_email, message.as_string())\n",
    "        server.quit()\n",
    "        print('successfully sent the mail.')\n",
    "    except smtplib.SMTPException as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "content = f\"BRAT is ready for iter_{config.current_iter}, sampling_num: {config.sampling_num}\"\n",
    "send_mail(['to email you want to send'], content=content, subject=content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sr_coref",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
