{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on MIMIC-CXR manual annotation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "sys.path.append(\"../../../../git_clone_repos/fast-coref/src\")\n",
    "\n",
    "import os\n",
    "import ast\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from IPython.display import display, HTML\n",
    "from common_utils.coref_utils import ConllToken\n",
    "# display(HTML(df.to_html()))\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from multiprocessing import Event\n",
    "from common_utils.data_loader_utils import load_mimic_cxr_bySection\n",
    "from common_utils.coref_utils import resolve_mention_and_group_num\n",
    "from common_utils.file_checker import FileChecker\n",
    "from common_utils.common_utils import check_and_create_dirs, check_and_remove_dirs, check_and_remove_file\n",
    "from coreference_resolution.data_preprocessing.mimic_cxr_csv2conll import copy_and_paste_conll\n",
    "from common_utils.coref_socring import invoke_conll_script, resolve_conll_script_output\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "FILE_CHECKER = FileChecker()\n",
    "START_EVENT = Event()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conll_score(conll_file_gt, conll_file_pred):\n",
    "    print(\"gt:\", conll_file_gt)\n",
    "    print(\"pred:\", conll_file_pred)\n",
    "    scorer_path = \"./wrong_conll_scorer_example/reference-coreference-scorers/scorer.pl\"\n",
    "    overall_f1 = []\n",
    "    for metric in ['muc', 'bcub', 'ceafe']:\n",
    "        out, err = invoke_conll_script(scorer_path, metric, conll_file_gt, conll_file_pred)\n",
    "        mention_recall, mention_precision, mention_f1, coref_recall, coref_precision, coref_f1 = resolve_conll_script_output(out)\n",
    "        overall_f1.append(coref_f1)\n",
    "        print(f\"Metric: {metric}\")\n",
    "        print(f\"mention_recall, mention_precision, mention_f1: {mention_recall}, {mention_precision}, {mention_f1}\")\n",
    "        print(f\"coref_recall, coref_precision, coref_f1: {coref_recall}, {coref_precision}, {coref_f1}\")\n",
    "\n",
    "    print(f\"Overall F1: {sum(overall_f1) / len(overall_f1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_csv_to_conll(section_name, doc_id, output_file_path, input_file_path_or_df, coref_group_conll_colName, sentence_group_colName,token_colName):\n",
    "    \"\"\" The whitespace tok contained in the csv file will be removed when being converted to conll file \"\"\"\n",
    "    BEGIN = f\"#begin document ({doc_id}_{section_name}); part 0\\n\"\n",
    "    SENTENCE_SEPARATOR = \"\\n\"\n",
    "    END = \"#end document\\n\"\n",
    "\n",
    "    # Resolve CSV file\n",
    "    sentenc_list: list[list[ConllToken]] = []\n",
    "    if isinstance(input_file_path_or_df, str):\n",
    "        df = pd.read_csv(input_file_path_or_df, index_col=0, na_filter=False)\n",
    "    else:\n",
    "        df = input_file_path_or_df\n",
    "\n",
    "    sentence_id = 0\n",
    "    while True:\n",
    "        token_list: list[ConllToken] = []\n",
    "        df_sentence = df[df.loc[:, sentence_group_colName] == sentence_id].reset_index()\n",
    "        if df_sentence.empty:\n",
    "            break\n",
    "        for _idx, data in df_sentence.iterrows():\n",
    "            # Skip all whitespces like \"\\n\", \"\\n \" and \" \".\n",
    "            if str(data[token_colName]).strip() == \"\":\n",
    "                continue\n",
    "            conllToken = ConllToken(doc_id+\"_\"+section_name, sentence_id, _idx, data[token_colName])\n",
    "            coref_col_cell = data[coref_group_conll_colName]\n",
    "            if isinstance(coref_col_cell, str) and coref_col_cell != \"-1\":\n",
    "                conllToken.add_coref_label(\"|\".join(ast.literal_eval(coref_col_cell)))\n",
    "            token_list.append(conllToken)\n",
    "        sentenc_list.append(token_list)\n",
    "        sentence_id += 1\n",
    "\n",
    "    with open(output_file_path, \"a\", encoding=\"UTF-8\") as out:\n",
    "        out.write(BEGIN)\n",
    "        for sent in sentenc_list:\n",
    "            # Skip empty sentence\n",
    "            if len(sent) == 1 and sent[0].tokenStr == \"\":\n",
    "                continue\n",
    "            for tok in sent:\n",
    "                out.write(tok.get_conll_str() + \"\\n\")\n",
    "            out.write(SENTENCE_SEPARATOR)\n",
    "        out.write(END)\n",
    "        out.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_list_to_conll(output_file_path, doc_id, section_name, old_sentenc_list):\n",
    "    BEGIN = f\"#begin document ({doc_id}_{section_name}); part 0\\n\"\n",
    "    SENTENCE_SEPARATOR = \"\\n\"\n",
    "    END = \"#end document\\n\"\n",
    "\n",
    "    sentenc_list: list[list[ConllToken]] = []\n",
    "    for sentence_id, old_token_list in enumerate(old_sentenc_list):\n",
    "        token_list: list[ConllToken] = []\n",
    "        for tok_idx, tok in enumerate(old_token_list):\n",
    "            # Skip all whitespces like \"\\n\", \"\\n \" and \" \".\n",
    "            if tok.tokenStr.strip() == \"\":\n",
    "                continue\n",
    "            conllToken = ConllToken(doc_id+\"_\"+section_name, sentence_id, tok_idx, tok.tokenStr)\n",
    "            conllToken.corefLabel = tok.corefLabel\n",
    "            token_list.append(conllToken)\n",
    "        sentenc_list.append(token_list)\n",
    "\n",
    "    with open(output_file_path, \"a\", encoding=\"UTF-8\") as out:\n",
    "        out.write(BEGIN)\n",
    "        for sent in sentenc_list:\n",
    "            # Skip empty sentence\n",
    "            if len(sent) == 1 and sent[0].tokenStr == \"\":\n",
    "                continue\n",
    "            for tok in sent:\n",
    "                out.write(tok.get_conll_str() + \"\\n\")\n",
    "            out.write(SENTENCE_SEPARATOR)\n",
    "        out.write(END)\n",
    "        out.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_singleton(df_pred, coref_group_conll_colName):\n",
    "    # remove singleton from df_pred\n",
    "    corefGroup_counter = Counter()\n",
    "    for conll_corefGroup_list_str in df_pred[~df_pred.loc[:, coref_group_conll_colName].isin([\"-1\", -1.0, np.nan])].loc[:, coref_group_conll_colName].to_list():\n",
    "        for conll_corefGroup_str in ast.literal_eval(conll_corefGroup_list_str):\n",
    "            result = re.search(r\"(\\d+)\\)\", conll_corefGroup_str)  # An coref mention always end with \"number)\"\n",
    "            if result:\n",
    "                corefGroup_counter.update([int(result.group(1))])\n",
    "\n",
    "    non_singletone_counter: list[tuple] = list(filter(lambda item: item[1] > 1, corefGroup_counter.items()))\n",
    "    coref_group_list_notSingleton = [int(k) for k, v in non_singletone_counter]\n",
    "    \n",
    "    # iter df rows, keep only the non_singleton coref id, and remove the others.\n",
    "    for idx, item in df_pred.iterrows():\n",
    "        conll_corefGroup_list_str = item.get(coref_group_conll_colName)\n",
    "        new_conll_corefGroup_str_list = []\n",
    "        # Remove singleton id\n",
    "        if conll_corefGroup_list_str in [\"-1\", -1.0, np.nan]:\n",
    "            continue\n",
    "        for conll_corefGroup_str in ast.literal_eval(conll_corefGroup_list_str):\n",
    "            res = re.match(r\"\\(?(\\d+)\\)?\",conll_corefGroup_str)\n",
    "            coref_group_id = int(res.groups()[0])\n",
    "            if coref_group_id in coref_group_list_notSingleton:\n",
    "                new_conll_corefGroup_str_list.append(conll_corefGroup_str)\n",
    "        df_pred.loc[idx,coref_group_conll_colName] = str(new_conll_corefGroup_str_list) if new_conll_corefGroup_str_list else -1\n",
    "    \n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input_tok_as_realworld(df_base, spacy_nametyle):\n",
    "    \"\"\" \n",
    "    Format the input token without any additional processing. \n",
    "    For example, the whitespaces before and after sentences are all remained.\n",
    "    \"\"\"\n",
    "    tok_list = df_base.loc[:, spacy_nametyle.token].to_list()\n",
    "    sentGroup_list = df_base.loc[:, spacy_nametyle.sentence_group].to_list()\n",
    "    sent_tok_2d_list: list[list[str]] = []\n",
    "    for tok, sent_id in zip(tok_list, sentGroup_list):\n",
    "        tok = str(tok)  # In i2b2, some of the tokens might incorrectly be recognized as float type.\n",
    "        if len(sent_tok_2d_list) == sent_id:\n",
    "            sent_tok_2d_list.append([tok])\n",
    "        else:\n",
    "            sent_tok_2d_list[sent_id].append(tok)\n",
    "    return sent_tok_2d_list\n",
    "\n",
    "def format_input_tok_same_as_traingset(df_base, spacy_nametyle):\n",
    "    \"\"\" \n",
    "    Format the input token by using the same approach as creating training sets for fast-coref models \n",
    "    For example, we skipped all whitespces like \"\\n\", \"\\n \" and \" \".\n",
    "    \"\"\"\n",
    "    sent_tok_2d_list: list[list[str]] = []\n",
    "    sentence_id = 0\n",
    "    index_map= [] # map the input token index to the spacy token index.\n",
    "    curr_spacy_index = 0\n",
    "    while True:\n",
    "        token_list2: list[str] = []\n",
    "        df_sentence = df_base[df_base.loc[:, spacy_nametyle.sentence_group] == sentence_id].reset_index()\n",
    "        if df_sentence.empty:\n",
    "            break\n",
    "        for _idx, data in df_sentence.iterrows():\n",
    "            # Skip all whitespces like \"\\n\", \"\\n \" and \" \".\n",
    "            curr_spacy_index += 1\n",
    "            if str(data[spacy_nametyle.token]).strip() == \"\":\n",
    "                continue\n",
    "            conllToken = data[spacy_nametyle.token]\n",
    "            token_list2.append(conllToken)\n",
    "            index_map.append(curr_spacy_index-1)\n",
    "            \n",
    "        sent_tok_2d_list.append(token_list2)\n",
    "        sentence_id += 1\n",
    "    return sent_tok_2d_list, index_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_to_spacy(tok_indices_in_spacy, label_aligned_to_input, input_tok_list, spacy_tok_list):\n",
    "    aligned_to_spacy_tok = [-1] * len(spacy_tok_list)\n",
    "    for idx_in_spacy, label, input_tok in zip(tok_indices_in_spacy, label_aligned_to_input, input_tok_list):\n",
    "        assert input_tok == spacy_tok_list[idx_in_spacy]\n",
    "        aligned_to_spacy_tok[idx_in_spacy] = label\n",
    "    return aligned_to_spacy_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modify this if gt file has changed###\n",
    "output_dir = \"../../resources/eval\"\n",
    "source_input_csv_dir = \"../../output/mimic_cxr/manual_test_set/round1x2_new\"\n",
    "source_input_conll_dir = \"../../output/mimic_cxr/coref/individual_conll_ground_truth/round1x2_new\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of gt docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dict_allDoc:dict[str,list] = {}\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    gt_all_dir = os.path.join(source_input_csv_dir, section_name)\n",
    "    gt_dict_allDoc[section_name] = [i.rstrip(\".csv\") for i in FILE_CHECKER.filter(os.listdir(gt_all_dir))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of gt docs that has coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dict_hasCoref:dict[str,list] = {}\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    gt_all_dir = os.path.join(source_input_conll_dir, section_name)\n",
    "    gt_dict_hasCoref[section_name] = [i.rstrip(\".conll\") for i in FILE_CHECKER.filter(os.listdir(gt_all_dir))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general gt conll file\n",
    "\n",
    "The conll file is equivalent to the conll file used in fast-coref models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_conll_file_gt = os.path.join(output_dir, \"gt_200_noWhich_new.conll\")\n",
    "check_and_remove_file(output_conll_file_gt)\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = gt_dict_allDoc[section_name]\n",
    "    for doc_id in doc_list:\n",
    "        input_conll_file = os.path.join(source_input_conll_dir, section_name, f\"{doc_id}.conll\")\n",
    "        if os.path.exists(input_conll_file):\n",
    "            copy_and_paste_conll(input_conll_file, output_conll_file_gt)\n",
    "        else:\n",
    "            input_csv_file = os.path.join(source_input_csv_dir, section_name, f\"{doc_id}.csv\")\n",
    "            from_csv_to_conll(section_name, doc_id, output_conll_file_gt, input_csv_file, \"[gt]coref_group_conll\", \"[sp]sentence_group\",\"[sp]token\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1-1: ensemble (majority voting)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Eval (has coref / no coref)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of predict docs that has coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_hasCoref: dict[str, list[str]] = {}\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    ensemble_dir = os.path.join(\"../../output/mimic_cxr/coref/individual_conll\", section_name)\n",
    "    pred_dict_hasCoref[section_name] = [i.rstrip(\".conll\") for i in FILE_CHECKER.filter(os.listdir(ensemble_dir))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = {}\n",
    "false_positive = {} # predict true, actual false\n",
    "false_negative = {} # predict false, actual true\n",
    "true_negative = {}\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    pred_hasCoref = set(pred_dict_hasCoref[section_name])\n",
    "    gt_hasCoref = set(gt_dict_hasCoref[section_name])\n",
    "    gt_all = set(gt_dict_allDoc[section_name])\n",
    "\n",
    "    true_positive[section_name] = pred_hasCoref.intersection(gt_hasCoref)\n",
    "    false_positive[section_name] = gt_all.intersection(pred_hasCoref) - gt_hasCoref\n",
    "    false_negative[section_name] = gt_hasCoref - pred_hasCoref\n",
    "    true_negative[section_name] = gt_all - pred_hasCoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "findings\n",
      "true_positive 62\n",
      "false_positive 0\n",
      "false_negative 38\n",
      "true_negative 38\n",
      "impression\n",
      "true_positive 62\n",
      "false_positive 0\n",
      "false_negative 38\n",
      "true_negative 38\n"
     ]
    }
   ],
   "source": [
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    print(section_name)\n",
    "    print(\"true_positive\",len(true_positive[section_name]))\n",
    "    print(\"false_positive\",len(false_positive[section_name]))\n",
    "    print(\"false_negative\",len(false_negative[section_name]))\n",
    "    print(\"true_negative\",len(true_negative[section_name]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'micro':\n",
    "Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "\n",
    "'macro':\n",
    "Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "\n",
    "'weighted':\n",
    "Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
    "\n",
    "'binary':\n",
    "Only report results for the class specified by pos_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[124  76]\n",
      " [  0   0]]\n",
      "\n",
      "precision, recall, f1, support(class_ele_num):\n",
      "micro: (0.62, 0.62, 0.62, None)\n",
      "macro: (0.5, 0.31, 0.38271604938271603, None)\n",
      "weigthed macro: (1.0, 0.62, 0.7654320987654321, None)\n",
      "binary has_coref [[  1.          0.62        0.7654321 200.       ]]\n",
      "binary no_coref [[0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuxiangliao/anaconda3/envs/sr_coref/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yuxiangliao/anaconda3/envs/sr_coref/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yuxiangliao/anaconda3/envs/sr_coref/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "y_true = [\"has_coref\" if doc_id in gt_dict_hasCoref[section_name] else \"no_coref\" for section_name, doc_list in gt_dict_allDoc.items() for doc_id in doc_list]\n",
    "y_pred = [\"has_coref\" if doc_id in pred_dict_hasCoref[section_name] else \"no_coref\" for section_name, doc_list in gt_dict_allDoc.items() for doc_id in doc_list]\n",
    "confusion_arr = confusion_matrix(y_true, y_pred, labels=[\"has_coref\",\"no_coref\"])\n",
    "# TP FN\n",
    "# FP TN\n",
    "print(confusion_arr)\n",
    "print()\n",
    "\n",
    "micro_precision_recall_f1 = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "macro_precision_recall_f1 = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "weigthed_precision_recall_f1 = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "binary_precision_recall_f1 = precision_recall_fscore_support(y_true, y_pred, average=None, labels=[\"has_coref\",\"no_coref\"])\n",
    "precision,recall,f1,support = binary_precision_recall_f1\n",
    "\n",
    "print(\"precision, recall, f1, support(class_ele_num):\")\n",
    "print(\"micro:\", micro_precision_recall_f1)\n",
    "print(\"macro:\", macro_precision_recall_f1)\n",
    "print(\"weigthed macro:\", weigthed_precision_recall_f1)\n",
    "for i,j in zip([\"has_coref\",\"no_coref\"],np.matrix([precision,recall,f1,support]).getT()):\n",
    "    print(\"binary\",i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAHBCAYAAABHW5BvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABZeklEQVR4nO3dd1gUV9sG8HvpCIiIBRBjwV6iiF2xRWNiC/aoscUSU2xoCkQ/UGNJsyZWiMREfUWNlaCxYotiw4oNUVSqSG8L7Hx/EDZudkBYBnaE+/de57rCmTNnnvV19fG0UQAQQERERCRDBvoOgIiIiKggTFSIiIhItpioEBERkWwxUSEiIiLZYqJCREREssVEhYiIiGSLiQoRERHJFhMVIiIiki0mKkRERCRbTFSIqMgEQcCJEyc06jZv3gxBEFCnTh09RUVE5RkTFSLSKy8vLwiCgO7du+s7FCKSISYqRFQiHh4eaNKkCZ49e6bvUIioHDLSdwBE9HqLjo5GdHS0vsMgonKKIypEMtO9e3cIggAvLy906dIFJ06cQHJyMhISErBr1y44OTlptA8PD0d4eDisra2xZs0aREREIDs7G+PHj1e3admyJbZv347IyEhkZWXh0aNHWL16NapWrSoaw6RJk3Djxg1kZGQgIiIC3377LUxNTUXbFrZGxdXVFXv27EF0dDQyMzMRERGB3bt3o0uXLgCAEydOwNvbGwBw8uRJCIIAQRAQHh6uyy8dEZVDHFEhkqmOHTvCw8MDhw4dwpo1a9C8eXMMHjwYrq6u6Nixo8Zf5qampjh+/DgsLS2xf/9+5OTkICYmBgAwcOBA+Pv7Q6VSYd++fXjy5AmaNWuG6dOno2/fvujQoQMSExPVfc2bNw+LFi1CdHQ0Nm3ahOzsbIwcORJNmzYtVvwzZszAihUrkJGRgT179iAiIgK1atVC165dMWzYMJw9exZ+fn4AgB49esDPzw+PHj0CAI14iIgEFhYW+ZTu3bsL+aZOnapxberUqYIgCML+/fvVdeHh4YIgCEJgYKBgZmam0b5q1apCYmKi8OTJE+GNN97QuDZy5EhBEARh9erV6jonJydBqVQKT548EapXr66ut7KyEkJDQwVBEIQTJ05o9LN582ZBEAShTp066ro333xTyMnJEZ4+fapRn1/s7e3V/+3l5SUIgiB0795d77/2LCwssix6D4CFheWlkp+o3LlzR1AoFBrXFAqFcPfuXSE3N1eoVq2aAPybqLRs2VKrr1mzZgmCIAgffPCB6LMuXbokxMbGqn+eP3++IAiCMHv2bK22Y8aMKXKi8vPPPwuCIAgTJkx45edlosLCwlJY4dQPkUydPXsWgiBo1AmCgLNnz6JRo0Zo1aoVjh07BgDIyMjAjRs3tPro2LEjAKBDhw5aa1sAwMzMDNWrV4etrS3i4+PRqlUrAMDp06e12orVFaR9+/YAgL/++qvI9xARiWGiQiRT+WtMCqq3trZW18XGxoq2zV8s+9lnnxX6LAsLC8THx6v7FOuvoHjEWFtbQ6VSISoqqsj3EBGJ4a4fIpmqWbNmofVJSUnquv+OvORLTk4GALRo0QIKhaLAEhERodFnjRo1ihyPmMTERBgYGMDe3r7I9xARiWGiQiRTXbp0gUKh0KhTKBTo3LkzVCoVrl279so+Lly4AADo1KlTkZ6Z36erq6vWNbG6ggQHBwMA3n777Ve2zc3NBQAYGhoWuX8iqjiYqBDJVOPGjTFlyhSNuilTpqBx48YICAjA8+fPX9nH5s2bkZycjMWLF6NZs2Za183NzdGhQwf1z9u2bUNOTg7c3d1RvXp1db2VlRXmzZtX5NjXr1+PnJwcfPPNN3jjjTe0rr880vLixQsAQO3atYvcPxFVHFyjQiRThw4dwurVq9GvXz/cunULzZs3x8CBAxEXF4eZM2cWqY/nz59j1KhR2LlzJ65du4ZDhw7hzp07MDU1Rd26ddG9e3ecO3cO7777LgAgLCwMCxcuxMKFC3H9+nX4+/sjJycHQ4cOxfXr19GkSZMiPffmzZuYNWsWVq9ejVu3bmHv3r14/Pgx7Ozs0K1bNwQEBGD27NkA8g59U6lUWLJkCZo3b46kpCQkJibi559/1u0XjojKHb1vPWJhYfm35G9P9vLyErp06SKcOHFCSElJERITE4Xdu3cLTk5OGu3Dw8OF8PDwQvts1KiRsGnTJiE8PFzIzMwU4uPjhWvXrgkrV64U2rZtq9V+0qRJws2bN4XMzEwhIiJC+O677wQzM7Mib09++bPs379feP78ubqvnTt3Cp06ddJoN27cOOHatWtCRkaGIAjCKz8PCwtLhSp6D4CFheWl8nKiou9YWFhYWPRduEaFiIiIZIuJChEREckWExUiIiKSLQXy5oCIiIiIZIcjKkRERCRbTFQqEC8vLwiCAFtbW32HImsffPABQkNDoVQqkZCQoO9wiPSibdu2OHv2LFJTUyEIgvqFlURljQe+Eb2kcePG8PPzw6FDh7Bs2TKkp6frOySiMmdkZISdO3ciMzMTs2fPRnp6Oh4/fqzvsKiCYqJC9JIePXrA0NAQM2fORFhYmL7DIdILJycn1K1bF5MnT4avr6++w6EKjlM/VK5VqlSpWO3z3xqcmJhYCtEQ6YepqanWCy4Lw+8ByQkTlQqoSpUq2Lx5MxISEpCYmIhffvkF5ubm6usTJkzAsWPHEBMTg8zMTNy6dQvTpk3T6sfFxQWHDh1CXFwc0tPT8fDhQ53+9dW+fXsEBATgxYsXSE1NxbVr1zBjxgyNNj179sSpU6eQmpqKhIQE7N27V+u9M/lrcJo2bYqtW7fixYsXOHPmjPr6mDFjcOnSJaSnpyM+Ph7bt2+Ho6Oj+np4eDgWLlwIIO8dOYIgwMvLq9ifh15/+b+XnJycCv2uGBoaYt68eXjw4AEyMzMRHh6OxYsXw8TEpNjPdHBwgI+PD549e4bMzEw8fPgQa9euhbGxsbpNvXr14O/vj/j4eKSlpeHvv/9Gv379NPrp3r07BEHAyJEjsWjRIjx9+hTp6emoXLkygLzvW2BgIBITE5GWloaTJ0+ic+fO6vs3b96MU6dOAQB27doFQRBw4sSJYn8eIqlw6qcC8vf3R3h4ODw8PNCmTRtMmTIFsbGx+OqrrwAAH3/8MW7duoX9+/cjJycHAwcOxLp162BgYIC1a9cCAKpXr46//voLcXFxWLZsGRITE1G3bl0MGTKkWLH07t0bBw8eRFRUFFatWoXo6Gg0bdoUAwYMwOrVqwEAb731FgIDA/Hw4UN4e3vD3Nwc06dPx9mzZ9GmTRutufOdO3fi/v378PT0VP8r0tPTE4sWLYK/vz98fHxQvXp1TJ8+HadOnYKzszOSkpIwa9YsjBs3DkOGDMG0adOQmpqK69evl/SXm15jr/qu+Pj4YMKECdi5cyd+/PFHdOjQAZ6enmjatGmxvgv29vYIDg5GlSpVsHHjRty5cwe1atXCsGHDUKlSJSQlJaFGjRo4d+4cKlWqhNWrVyM+Ph7jx4/H/v37MWzYMOzdu1ejz/nz50OpVOKHH36AqakplEolevbsicDAQFy+fBkLFiyASqXCxIkTcfz4cbi6uuLixYvYsGEDnj17hq+//hqrVq3CxYsXERMTI+UvK1Gx6f0cf5ayKV5eXoIgCIKPj49G/e7du4W4uDj1z2ZmZlr3BgYGCg8ePFD//N577wmCIAguLi46x2NgYCCEhYUJ4eHhgrW1dYHtrly5IkRHRws2NjbqupYtWwo5OTmCn5+f1ufbunWrxv1vvPGGkJ2dLXh4eGjUN2/eXFAqlRr1+X3Y2trq/f8vFv2VonxX3nzzTUEQBGHjxo0abb777jtBEAShR48eRX6en5+fkJOTU+j3afny5YIgCEKXLl3UdRYWFkJYWJjw8OFDQaFQCMC/74p68OCB1nf57t27QmBgoEadmZmZEBYWJhw+fFhdl9/H0KFD9f7/BQsLp34qoPXr12v8fPr0aVSrVg1WVlYAgMzMTPW1ypUrw9bWFkFBQXByclIPH+fPXQ8YMABGRroNzDk7O6N+/fpYuXIlkpKSRNvY2dnB2dkZfn5+GluFb9y4gSNHjmgNe4t9viFDhsDAwAD+/v6wtbVVl+joaNy/fx89e/bUKX4q/wr7ruT/3lu+fLlGmx9//BEA0L9//yI9Q6FQwM3NDQcOHMDly5cLbNevXz9cuHABZ8+eVdelpaVh48aNqFevHpo1a6bR/tdff9X4Lrdu3RqNGjXCtm3bNL4HFhYWOHbsGLp161asdSxEZYVTPxVQRESExs/5CYCNjQ1SUlLQuXNnLFiwAJ06dYKFhYVGW2trayQnJyMoKAi7du2Ct7c3Zs+ejZMnT2Lv3r3Ytm0blEplkeJwcnICANy8ebPANnXq1AEA3L17V+taaGgo3nnnHVSqVEljG3F4eLhGu4YNG8LAwAAPHjwQfUZ2dnaR4qWKp7DvSp06dZCbm6v1+yomJgYJCQnq37uvUr16dVhbWxf6PQDyvgsXLlzQqg8NDVVfv3Xrlrpe7HsAAFu2bCnwGdbW1lxAS7LDRKUCys3NFa1XKBSoX78+jh07hjt37sDd3R1PnjyBUqlEv3794O7uDgODfwfhhg8fjg4dOmDgwIHo27cvNm/ejDlz5qBjx45IS0srq4+jJSMjQ+NnAwMDqFQqvPvuu6KfPTU1taxCo9dMYd+VfIIglFU4xSL2PQCAuXPnIiQkRPQefhdIjpiokIaBAwfCzMwMgwYNwpMnT9T1BU2PXLhwARcuXMC8efMwatQobNu2De+//36Rdv/kn1PSokULHDt2TLRN/kLZxo0ba11r0qSJesfRq55jYGCA8PBw3L9//5VxERXF48ePYWhoiIYNG+LOnTvq+ho1asDGxqbIB6TFxcUhKSkJLVq0eOXzCvoe5F8vTP73LTk5ucDvG5EccY0Kacj/F+TL/2KsXLkyJk6cqNGuSpUqWvfm/yvN1NS0SM+6cuUKHj58iFmzZsHa2lq0TXR0NK5evYrx48drtGnevDnefvtt/Pnnn698zh9//IGcnJwCtxpXrVq1SPESvSz/996sWbM06t3d3QEAAQEBRepHEATs3bsXAwcOhIuLS6HP69ChAzp27Kiuq1SpEqZOnYrw8HDcvn270OdcvnwZDx48wNy5c7WmdAGgWrVqRYqXqKxxRIU0/PXXX8jKysKBAwewYcMGWFpaqrdkOjg4qNuNHz8en3zyCfbs2YOwsDBYWVlhypQpSEpKKlLyAOT9Af3xxx/jwIEDCAkJwebNmxEVFYUmTZqgefPmeOeddwAAn3/+OQIDA/H333/D19dXvT05KSkJ3t7er3zOw4cPMW/ePCxbtgx169bF3r17kZKSgnr16mHw4MHYuHGjegEkUVFdv34dfn5++Oijj1ClShUEBQWhffv2mDBhAvbs2YOTJ08WuS9PT0+8/fbbCAoKwsaNGxEaGgp7e3sMHz4cXbt2RVJSEpYtW4ZRo0YhMDAQq1evxosXLzB+/HjUq1cPQ4cOfeUUlCAImDx5MgIDA3Hr1i1s3rwZz549Q61atdCzZ08kJydj0KBBJfxVISodet96xFI2paCtt+PHjxcEQRDq1KkjABAGDBgghISECOnp6cLDhw+Fzz//XJgwYYJGm9atWwtbt24VHj16JGRkZAjR0dHC/v37hTZt2hQ7rs6dOwuHDx8WkpKShJSUFCEkJET49NNPNdr06tVLOH36tJCWliYkJiYK+/btE5o0aVKkz5dfBg8eLJw6dUpISUkRUlJShNu3bwtr1qwRGjZsWOQ+WCpGKep3xdDQUJg/f74QFhYmZGVlCY8fPxYWL14smJiYFPuZtWvXFvz8/ISYmBghIyNDePDggbBmzRrB2NhY3aZevXqCv7+/8OLFCyE9PV04f/680K9fP41+XrW1uFWrVsKuXbuEuLg4ISMjQwgPDxf+97//CT179ixyHywsZVkU//wHERERkexwjQoRERHJFteoUKmwsbEp9H0nubm5eP78eRlGRFT2LCwsYGlpWWibuLg4qFSqMoqI6PWk9/knlvJXTpw4IRQmPDxc7zGysJR2yV/rUpj89S4sLCzihWtUqFS0adMGNjY2BV7PyMjAuXPnyjAiorJXr1491K9fv9A2Z86cQVZWVhlFRPT6YaJCREREssXFtERERCRbTFSIiIhItpiokN6ZmJjAy8ur0F1CRBUNvxdEebhGhfTOysoKycnJqFy5MlJSUvQdDpEs8HtBlIcjKkRERCRbTFSIiIhItpioEBERkWxV6DUqyrgwfYdA/zCoZANVeoK+wyAAiaMm6jsEAgBjY1R6fwzS/7cVyM7WdzQVXo2jp0r9GVL+nWRS3UmyvvSN7/ohWWCSQvQf2dlI/81P31EQ6R0TFSIiIjlQ5eo7AlliokJERCQHAt+iLYaLaYmIiEi2OKJCREQkByqOqIjhiAoREZEMCIJKslIcFhYW8Pb2RmBgIOLj4yEIAsaPH6/RRqFQYPz48di3bx8iIiKQmpqKGzdu4Ouvv4apqalovx9++CFu376NjIwM3Lt3D5999plOvy5MVIiIiCqwatWqwcvLC02bNsW1a9dE21SqVAl+fn6oXr061q9fj1mzZiE4OBgLFixAYGCgVvupU6fC19cXt27dwvTp0/H3339jzZo1+OKLL4odH6d+iIiI5EBPUz9RUVGws7NDTEwMXFxccOnSJa02SqUSnTt3xt9//62u8/HxwaNHj7Bw4UK89dZbOHbsGADAzMwMixcvxsGDBzF8+HB1WwMDA8yfPx8bN25EYmJikePjiAoREZEcCCrpSjEolUrExMQU2iY7O1sjScm3Z88eAEDTpk3VdT179kS1atWwdu1ajbY///wzLC0t0b9//2LFx0SFiIiIdGJnZwcAeP78ubrO2dkZALRGZi5fvozc3Fz19aLi1A8REZEcSHjgm4mJidYi16ysLCiVSsmeAQBffPEFkpKSNNap2NvbIycnB3FxcRpts7OzER8fDwcHh2I9gyMqREREciDh1I+HhweSk5M1ioeHh6Thenh4oE+fPvjqq6+QlJSkrjc3Ny8wIcrMzIS5uXmxnsMRFSIiIjmQcDHt0qVLsXz5co26rKwsyfofMWIEvvnmG/j4+GD9+vUa1zIyMmBiYiJ6n5mZGTIyMor1LCYqRERE5YxSqZR8midf7969sWXLFgQEBGDatGla16OiomBkZITq1atrTP8YGxvD1tYWkZGRxXoep36IiIhkQF8HvhVH+/btsWfPHly6dAkjRoxAbq72upqQkBAAQNu2bTXq27ZtC0NDQ/X1omKiQkREJAcqlXSlFDRp0gQBAQF49OgRBgwYgMzMTNF2x48fR3x8PD7++GON+o8//hhpaWkICAgo1nM59UNERFTBffrpp6hSpYp6R87AgQPh6OgIAFizZg1UKhUOHz4MGxsbfP/991pnoYSFheH8+fMA8hbMzp8/H2vXroW/vz8OHz4MV1dXjB07Fp6enkhISChWbAoAQsk/4utJGRem7xCIZCdx1ER9h0AkOzWOnir1Z2TePS1ZX2aNXYvVPjw8HHXr1hW9ll//6NGjAu/38/PDxImaf3ZMnjwZc+bMQb169fDkyRP89NNPWLVqVbHiApio6DsEItlhokKkrUwSldCTkvVl1rSHZH3pG9eoEBERkWxxjQoREZEclOJundcZExUiIiI50NPbk+WOUz9EREQkWxxRISIikgNO/YhiokJERCQHnPoRxUSFiIhIBgRB+zh64hoVIiIikjGOqBAREckB16iIYqJCREQkB1yjIopTP0RERCRbHFEhIiKSA079iGKiQkREJAcq7voRw6kfIiIiki2OqBAREckBp35EMVEhIiKSA+76EcVEhYiISA44oiKKa1SIiIhItjiiQkREJAec+hHFRIWIiEgOmKiI4tQPERERyRZHVIiIiGRAEHjgmxgmKkRERHLAqR9RnPohIiIi2eKIChERkRzwHBVRTFSIiIjkgFM/ojj1Q0RERLLFERUiIiI54NSPKCYqREREcsCpH1FMVIiIiOSAIyqiuEaFiIiIZIsjKkRERHLAqR9RTFSIiIjkgImKKE79EBERkWxxRIWIiEgOuJhWFBMVIiIiOeDUjyhZTf3Ex8dj6NCh6p/nz5+P5s2b6zEiIiIi0idZJSqWlpaoVKmS+mdvb2+8+eabeoyIiIiojAgq6Uo5Iqupn7CwMAwbNgynT59GcnIyAMDCwgI2NjaF3peQkFAW4REREZUeTv2IUgAQ9B1Evg8++ACbN2+GQqEo1n1GRrrlW8q4MJ3uIyrPEkdN1HcIRLJT4+ipUn9G+h9LJeur0hAPyfrSN1mNqPz+++8IDg5Gjx49ULNmTXh7e2PPnj24fv26vkMjIiIqXeVsykYqskpUAODevXu4d+8eAGDixIn49ddfceDAAT1HRUREVMo49SNKdonKy+rXr6/vEIiIiMoGExVRstr1I8bKygpffvklDh06hCtXrqBdu3YAABsbG8yePRtOTk56jpCIiIhKi6xHVGrVqoWgoCDUrl0b9+/fR5MmTWBpaQkgb6fPRx99hDp16mDWrFn6DZSIiKikBNnsbZEVWScq33//PaysrNC6dWvExsYiNjZW4/revXsxYMAAPUVHREQkIU79iJL11M/bb7+N1atXIzQ0FIJIpvnw4UPUrl1bD5ERERGVDxYWFvD29kZgYCDi4+MhCALGjx8v2rZJkyYIDAxESkoK4uPjsWXLFlSrVk2rnUKhwOeff46HDx8iIyMD165dw/vvv69TfLJOVMzNzREXF1fgdSsrqzKMhoiIqBSpVNKVYqhWrRq8vLzQtGlTXLt2rcB2tWrVwqlTp9CgQQN4enrihx9+QP/+/XHkyBEYGxtrtF28eDG+++47HDlyBNOnT0dERAS2b9+OkSNHFvuXRdZTP7dv30a3bt2wceNG0etubm64evVqGUdFRERUCvR0jkpUVBTs7OwQExMDFxcXXLp0SbSdp6cnLCws4OLigidPngAAgoODcfToUUyYMAGbNm0CADg4OGDOnDn46aefMH36dACAj48PgoKC8P3332Pnzp1QFSOZkvWIysqVK/H+++/jiy++gLW1NQDAwMAATk5O2LJlCzp16oQVK1boOUoiIqLXl1KpRExMzCvbDR06FAcPHlQnKQBw7Ngx3L17FyNGjFDXvffeezAxMcHatWs17l+3bh1q166NTp06FSs+WY+obN26FXXq1ME333yDxYsXAwAOHToEhUIBlUoFT09P7Nu3T89REhERSUDGi2kdHBxQs2ZN0dGW4OBg9OvXT/2zs7MzUlNTERoaqtUu//rZs2eL/GxZJyoAsGTJEvz2228YOnQoGjRoAAMDA4SFheGPP/5AeHi4vsMjIiKShoTbk01MTGBqaqpRl5WVBaVSqVN/9vb2APKmif4rKioKtra2MDExgVKphL29vegITf69Dg4OxXq2bBMVc3NznD59Gps2bcKGDRuwcuVKfYdERET0WvDw8IC3t7dGnbe3NxYsWKBTf+bm5gDykp3/yszMVLdRKpUwNzd/ZbvikG2ikpGRgXr16oluSyYiIip3JJz6Wbp0KZYvX65RJ5Y8FFVGRgYAaI3SAICZmZlGm4yMjCK1KypZL6Y9dOgQ+vbtq+8wiIiISp+E25OVSiVSUlI0iq7TPsC/0zb5U0Avs7e3R3x8vLr//F1EYu0AIDIysljPlnWismjRIjRq1AhbtmxBly5d4ODgABsbG61CRET02hNU0hWJRUZGIjY2Fm3bttW61r59e4SEhKh/DgkJgYWFBZo2barRrkOHDurrxSHrROXWrVto1qwZxowZg6CgIERERCAuLk6rEBERUenavXs3BgwYAEdHR3Vdr1690LhxY+zcuVNdt2/fPiiVSnzyySca90+bNg1Pnz7FuXPnivVc2a5RAYCFCxdyjQoREVUIgkp/f999+umnqFKlinpHzsCBA9UJyZo1a5CcnIwlS5Zg+PDhOHHiBFatWgVLS0t8/vnnuH79OjZv3qzu69mzZ1i5ciW++OILGBsb4+LFi3Bzc0O3bt0wevToYh32BgAKABU2E1DGhek7BCLZSRw1Ud8hEMlOjaOnSv0ZaetmSNaXxceri9U+PDwcdevWFb1Wt25dPH78GADQrFkzLF++HF27doVSqURAQADmzJmj9dJghUKBL7/8Eh999BHs7e1x//59LF26FNu2bSv2Z3mtEpX8FcP5W5xKiokKkTYmKkTaynuiImeyXqMCALVr18Yvv/yC6OhopKamIjU1FdHR0fD19cUbb7yh7/CIiIikIePFtPok6zUqjRs3xpkzZ1ClShUcOXJEfRxvkyZNMG7cOAwcOBBdu3bFvXv39BwpERFRCelxjYqcyTpRWbZsGVQqFZydnXHz5k2Na82bN8exY8ewbNkyDBkyRE8REhERUWmS9dRP9+7dsXr1aq0kBcjbuvzTTz+hR48eZR8YERGR1CQ88K08kfWIirGxcaFH7aanp8PY2LgMIyIiIiol5SzBkIqsE5WrV69i8uTJ8PHxQXJyssY1KysrTJo0CVeuXNFTdOVfenoGftm2Czdu38WN23eRnJKKbzzd4da/j7qNSqXC/sBjOBp0FqH3w5CcnIJa9nZ4t3d3TBg1FKamJgX2f+XaTYz75HMAwOmA/8GmivUrY1IqlfjJ5zccOHQcySmpaNSgHqZPGYfO7dtotb164zaWr/VF6N0wWFhUQt9erpj10QRUqlS8F2IRvYrV51/B7O13C7we//5QqOKf5/1gZIRKw9+Hae+3YWhnByEtDdn37iJ15Y9QPX/1AZZm7/SD+fD3YWhnh9y4OGTs2Y3MfX9otTOwrQaLjz+DiUtbQGGA7GtXkbruJ6iitd9+SyRnsk5UvLy8cOjQIdy5cwebN29WL5pt3Lgxxo8fD1tbW3z66ad6jrL8SkhKxvrN22BfswYaN6iPi1eva7XJzMzCvCXL0ap5E4xw6wdbmyoIuRmKn31/x/lLIfhlzTIoFAqt+1QqFZasWAdzczNkZBR9u/nXi5fjyIkz+GCEG+rUdsDeP4/ik7n/h1/WLEObVi3U7e7cC8PkGR6oX7c2Pp8+BTFxz+G3fTcinkZi/Y+LdPsFISpAxsEDUF65rFmpUMBqhjtyY6L/TVIMDWH9zbcwbtYcGYEHkfvwIRRWljBq0gwKCwvgFYmKWf+BsJo1F1mnTiJjlz+MW74Jq89mQmFmiowd219qaA7rH1bCwMIC6du3Ajk5MB86HFV+XI2EaZMgpCQX/BDSHx5wKkrWicqJEyfQr18/fP/99/jqq680roWEhGDs2LE4efKkfoKrAKrb2uDk/q2oZlsVN0Pv4f3JM7XaGBsb4bf1P8K5ZTN13bBB76KWXU11stKpnbPWfTv3BSI69jmGDuiL33fuK1I8N27fReDRIMz5dBImjh4GABj0Tm+4jZ2GH9f+gq0b/n1T6KoNfqhsZYnNP30LSwsLAICDXU14f7sKZy9cRpcOLsX6tSAqTE7oLeSE3tKoM2reEgpzc2QdP6quMx86AsZvtkLi7M+Qc/dO8R5iYgKLiZORdf4ckhd5AQAyAw8CCgUsxoxDZsABCKmpec8Z5AYjx9pI+PQj5NzLe47y4gXYbNqMSsNHIu2XTSX4tFRqOPUjStaLaQHg2LFjaNOmDRwcHNCpUyd06tQJDg4OcHFxwfHjx/UdXrlmYmKCarZVC21jbGyskaTke6t7ZwDAw0cRWteSklOwZtMWfDZ5LKysLIscz18nzsDQ0ADD3/t3iN3U1ARDBvTFtZuhiIrJ+9doaloa/r54FQP69lInKQDw3rtvoZK5OQ4fP13kZxLpyqxXbwgqFTLzExWFAuaDhyLr7Om8JMXAEDA1LXJ/Jq2dYWBdBZkH9mrUZ+zfC4V5JZh06KSuM3Xtjuw7oeokBQByn0Qg++oVmHbrUZKPRaVJJUhXyhHZJyr5YmJiEBwcjODgYMTExOg7HHqF5/EJACC67mTNpi2oVtVGI+EoitB7YahTu5ZG8gEALZs1AgDcvZ930vC9sEfIyc1F8yYNNdoZGxujScP6uHOfJxJTKTM0hGn3Hsi5fROqmOi8qjp1YVitOnLDw2A5ay6qHTiE6gf/gs2GX2DcSnvU8b+MGuT9fs6+d1ejPuf+XQi5uerrUChgVL8+cv7TDgCy74TCsJYjFOZcp0WvD1knKtOnT8ehQ4cKvP7nn39i2rRpZRgRFdUvW3fB0qISunbUfCX43Qfh2LnvT3w+fQoMDQ2L1efz+BeoLjLCk18X+/yFut3L9Rptq1VF7PP4Yj2XqLhM2rbPG/049u+0j2GtvBe8mQ8ZDuNWrZGy6kckf78UMDGB9ZLvYFivfqF9GlS1hZCbAyExUfNCTg6E5GQY2FYDACisKkNhYgrVC+3f56oXed+N/LYkMzyZVpSsE5VJkybh9u3bBV6/ffs2pk6dWoYRUVFs/PV/OH/pKmZ9PBGV/zO1s3TlOnTt2FanNSKZWVkwEdmObmKSt7MoKyvrn3bKf+rF22b9c52otJj26g0hOxtZQSfUdfmjGArzSkj6Yjay/jqErL8OIekLd0ChQKURowrv1MQUyM4RvSRkK6H453ug+GennZCdrd1Q+c/v/WJMOVEZ4tSPKFknKk5OTupj88XcuXMHTk5ORerLxMQEVlZWGoWkF3g0CGs2bcGQAX3x/uABWtdCboTi88+m6NS3makplCJ/+Cr/+cPX9J8/fM3++YNaqRRvW9iWaaISMzOHaacuUF66qLG7Rvgnkc6+dROquH9396jiYpF98waMm7fQ6kqDMgswFt//oDA2gfDP90D4JxFXiJ0x9U8yg39iIXodyDpRUSqVsLOzK/C6vb09VEVcJe3h4YHk5GSNYlDJRqpQCcC54Cvw/OYHdOvcDv/3+XSt6z+u9UXfnl1hbGyMZ1ExeBYVg5SUvF0K0bFxiI0rfEqmmm1VxP0zrfOy/Loa1aqq271cr9H2+QvUqGZbvA9GVAymXbr+s9vniEZ9/hZlVWKC1j2qxAQoLAv/x5PqRTwUhkZQVKmiecHICIrKldX9CynJEJRZMKiq/fvcoGpVjVhIXgSVSrJSnsg6UTl//jwmTJgAS0vtnSGVK1fGxIkTcf78+SL1tXTpUlSuXFmjqNK1/8Ag3Vy/dQczPReheZNG+HGRJ4yMtNefRMfEIeDISfQdNkFd8rcmD584HR/P/b9Cn9GkYX08fvIMqWlp/3l23qLBxg3zRtca1q8LI0ND3LpzX6NddnY27tx/iMYNC18LQFQSZr36QJWejqy/z2rU54Y/hJCdLbo+xMC2GlRJiYX2m/PgAQDAuFFjjXqjRo2hMDRETljedQgCcsLDYfSfdgBg3LQZciOfQSjkxG/SI079iJL1OSoLFixAUFAQQkJCsHLlSty6lXdOQYsWLTBr1izY29tj9OjRRepLqVSqpwhIWmGPIvDJ5155Z6d85w2zAua/Vy2dr1UXeDQIh46dwpL5c2FX/d8/wBMSk5CQlAz7mtVhbmYGAHi7Z1f4bd+NnfsC1eeoKJVK7P3zCN5s1hj2NasDAKwsLdCxnTMOHj6OaRNGwcKiEgBg/6HjSM/IQN+erpJ+fqJ8CmtrGLdxQdaJY1rTK0JGBpTB52HSsRMMa7+B3Cd5W/cN36gD4+bNkRlw4N/GpqYwrFETqqQkCMlJAABlyBWokpNgNsANyuAL6qbmA93y+r7wt7ou6/RJWE6eBqNGjdW7fwwda8O4tTMydu4opU9PVDpknagEBwdj4MCB2LBhA1atWgXhn1P7FAoFwsPDMWjQoCKPqJButu3aj5TUNPVOmZNnLyAmLm/YePSwQTBQKPCR+zwkp6Ri4uihOPX3RY37a9eyR+sWTQEAb3XrrNX/nfsPAQCuHdtqbGXetvsA1v2yFb+s+Rbt27wJAHizeRP07eWKVev98CIhCW842mNf4DFERsVgoccsjX5nTB2PD6a5Y8JnX2DYoHcRE/ccv27/A53bt9HaiUQkFdMevaAwMkLmf6Z98qX9sgnGzi6w/n4FMvbsBgCYDx4KITkF6dt+V7czbtwUVX5chbQtm5H+m19epVKJNL9fYDVjNirPXwDlpWAYt3gTZr3fRtovmyCkpKjvz9y/F+bvDoD1N8uQvnNH3sm0w0ZAlZCA9F1MVGSrnO3WkYqsExUAOHr0KBo0aABnZ2f1wtmwsDC+46eM+G3fjcjoWPXPR4PO4mhQ3pD2gL69AORN6QDAinWbte5/793e6kRFCkvmzcWamltw4PCxvHf9ONXDz98vQNvWLTXaNWvcAD4rl2D5us34bvVGWFQyx5ABfTFr2gTJYiH6L7NefaBKeIHs/x6n/4/ciMdImjMDFpOnwWLMWAgqAdkhV5C2aV2R1o1kHtirTjosO3aGKi4WqWvXIGPPLo12QkYGEufOguXHn6HSmLH/vOsnBKnrf4KQlCTFR6XSUM6mbKSiAFBufmVsbW0RHByMMWPGFGmkRRnHg7+I/itx1ER9h0AkOzWOnir1Z6QuKNpShqKw9NomWV/6JvsRleIwNDRE3bp1Yc5TF4mI6HVTznbrSKVcJSpERESvLU79iGKiQkREJAdcTCtK1ueoEBERUcXGERUiIiI54NSPKCYqREREMlDejr6XCqd+iIiISLbK1YiKUqlEUFAQEhL4Dh8iInrNcOpH1GuXqJibm+P999+Hqakp/vzzT0RERKivJSYmolevXnqMjoiISEdMVETJOlHx8fFBhw4d0LJl3vHoxsbGOH/+PFq0aAEASEpKQq9evRASEqLHKImIiKi0yHqNSs+ePfHHH3+ofx49ejRatGiBMWPGoEWLFoiOjoaXl5ceIyQiIpKIoJKulCOyTlTs7Ozw6NEj9c9ubm64dOkS/ve//yE0NBSbNm1Chw4d9BcgERGRVFSCdKUckXWikpaWhipVqgDIe49Pjx49cPjwYfX1lJQUWFtb6yk6IiIiKm2yXqNy5coVTJkyBSdOnMCgQYNgZWWFAwcOqK87OTkhJiZGjxESERFJQyhnIyFSkXWi8vXXX+Pw4cO4dOkSFAoFdu3ahYsXL6qvDx48GGfPntVjhERERBJhoiJK1onK5cuX0aRJE3Tu3BmJiYk4deqU+pq1tTXWrl2LoKAgPUZIREQkEZ5MK0rWiQoAPH/+HPv379eqT0pKwurVq/UQEREREZUV2Scq+SwtLWFtbQ0DA+31v0+ePNFDRERERBLi1I8o2Scq06ZNg7u7O+rXr19gGyMj2X8MIiKiwjFRESXr7ckfffQRfv75Zzx48ADz5s2DQqHAypUrsWzZMkRHR+PatWuYNGmSvsMkIiKiUiLrRGX69Ok4fPgw+vXrh40bNwIAAgICMG/ePDRr1gxWVlawtbXVc5REREQlJwiCZKU8kXWi4uTkpD43JTs7GwBgYmICAEhOToaPjw8++eQTvcVHREQkGZ5MK0rWiUpSUpJ6/UlKSgrS09NRu3Zt9fWUlBTY2dnpKzwiIiIqZbJOVG7evIlWrVqpfz5//jw+/vhjODg4wNHRER999BHu3bunxwiJiIgkwhEVUbLeLvP7779j2rRpMDExgVKphJeXF44ePYqIiAgAedNBQ4cO1XOUREREJccj9MUpALxWvzL16tXDoEGDkJOTg7/++gv379/XuS9lXJiEkRGVD4mjJuo7BCLZqXH01KsblVDihLck66uK3zHJ+tI3WY+ovMzCwgI2NjbIycnBH3/8oa6vXbs2D3wjIqLXH0dURMl6jYqpqSmWLFmCmJgYJCUl4dGjRwgPD9cqRERErz2VhKUYGjRogO3bt+PJkydIS0tDaGgo5s+fD3Nzc412nTp1wunTp5GWloaoqCisWrUKFhYWOn/coirxiErNmjXh4uKCKlWqwNDQULTNb7/9plPfa9euxfjx47F3716cPn0aCQkJJQmViIhItvSxRsXR0RHBwcFISkrCTz/9hBcvXqBTp05YuHAhXFxc4ObmBgBo1aoVjh07htDQULi7u8PR0RFz585Fw4YN0a9fv1KNUedExdTUFJs2bcL7778v+v4dAFAoFBAEQedEZciQIfDx8cG0adN0DZOIiIgKMHbsWNjY2KBr1664ffs2AGDTpk0wMDDA+PHjUaVKFSQmJmLJkiVISEhAjx49kJKSAgB49OgRfHx80KdPHxw5cqTUYtQ5UVm2bBnGjBmDe/fuYfv27Xj69ClycnKkjA2CIODKlSuS9klERCRLehhRqVy5MgAgJiZGoz4qKgq5ublQKpWwsrJCnz59sGLFCnWSAgBbtmzBihUrMGLECHkmKiNGjMDt27fh4uICpVIpZUxq+/btQ+/evdXH5xMREZVbxVxbIoWTJ0/iq6++gq+vL7y8vBAfH4/OnTvj448/xurVq5Geno7OnTvD2NgYly5d0rg3OzsbISEhcHZ2LtUYdV5MW6VKFRw6dEjSJMXGxkajLFq0CPXr18eGDRvQpk0bVKtWTauNjY2NZM8nIiIqD0xMTGBlZaVR8l9B87LDhw9j3rx56NOnD0JCQvDkyRPs2LEDa9asgbu7OwDA3t4eQN4oy39FRUXBwcGhVD+LziMqd+/eRc2aNaWMBc+fP9d6mZJCoYCzs3Ohb0nOP2afiIjodSXlYloPDw94e3tr1Hl7e2PBggVabR89eoRTp05h9+7diI+PR//+/eHp6Yno6Gj8/PPP6t0/WVlZWvdmZmZq7Q6Sms5/w3///fdYv349nJycEBYmzcFpCxcuLHdvfSQiIioSCad+li5diuXLl2vUiSUaI0eOxMaNG9GoUSM8e/YMALBnzx4YGBjg22+/xfbt25GRkQEgbxPNf5mZmamvl5YiJyqurq4aPz99+hSHDx9GcHAwVq5ciStXriA5OVn03tOnTxfpGWKZHhERERWPUqks0tKMTz75BFevXlUnKfn279+PiRMnwtnZWT3lkz8F9DJ7e3tERkZKE3QBipyonDx5UnS0Q6FQwNvbu9CREE7NEBERFU4f56jUrFlT9IwyY2NjAHl/f9+8eRPZ2dlo27Ytdu7cqdGmdevW8Pf3L9UYi5xBcFqGiIioFOlh18+9e/fw9ttvo2HDhhrvzhs1ahRyc3Nx/fp1JCcn4+jRo/jggw+waNEipKamAsg7g8XKykojeSkNr91LCaXElxISaeNLCYm0lcVLCeMHdZOsL9v9RYvX1dUVx48fR3x8PH766SfEx8djwIAB6NevHzZt2oSpU6cCAJydnXHu3Dncvn0bGzduhKOjI+bMmYNTp07hnXfekSxuMTpvT3Z1dUXt2rULbePo6Ki1toWIiIi0CSrpSlGdPn0anTt3xuXLl/HJJ59g5cqVcHJygqenJz7++GN1u6tXr6J3797IyMjAihUrMHXqVPj6+mLYsGGl8CuhSecRlZycHCxYsACLFi0qsI2npycWLlwo2zUqHFEh0sYRFSJtZTGi8ryfdCMq1f4s/XjLis4ZhEKheGUbAwMDrmshIiIqguKMhFQkOk/9FEXDhg2RlJRUmo8gIiKicqxYIyq+vr4aP7u5uaFu3bpa7QwNDVG7dm1069YNgYGBJQqQiIioQuCIiqhiJSoTJkxQ/7cgCGjdujVat24t2lYQBFy8eBGzZ88uSXxEREQVAqd+xBUrUalXrx6AvPUpDx8+xMqVK7Fq1Sqtdrm5uUhISEB6ero0URIREVGFVKxEJSIiQv3fEydOREhIiEYdERER6YYjKuJ03vWzZcsWKeMgIiKq0JioiNM5URk7dmyR2/7222+6PoaIiIgqMJ0TFT8/v1eekaJQKCAIAhMVIiKiVxFefT5ZRaRzojJxovjpldbW1mjTpg1Gjx6N/fv348CBAzoHR0REVFFw6kdcqa1R2bBhA44fP45169bp+ggiIiKq4ErtZNrz589j//79WLhwYWk9goiIqNwQVArJSnlSqkfoP378GK1atSrNRxAREZUL+nh78uugVF9r3K1bN2RkZJTmI4iIiMoFgYtpRemcqLi6uop3aGSEWrVqYdy4cWjXrh3PWyEiIiKd6ZyonDx5stDtyQqFAmfPnoW7u7uujyAiIqowytuUjVR0TlQWLlwomqioVCokJCTg4sWLCA4OLlFwREREFUV5WwQrFZ0TlQULFkgZBxEREZEWnXf9HDt2jFuPiYiIJCII0pXyROdEpUOHDjA0NJQyFiIiogqL56iI0zlRuXPnDurUqSNlLEREREQadE5U1qxZg/feew9NmzaVMh4iIqIKiSMq4nReTPvw4UOcPHkS58+fx4YNG3Dx4kXExMSI7gQ6ffp0iYIkIiIq78rb2hKplPgcFYVCgTlz5hR6poqRUakegEtERETllOTnqBAREVHxlbcpG6nwHBUiIiIZ4Lt+xOm8mNbV1RW1a9cutI2jo2OB7wQiIiKif/HtyeJ0TlROnDiBCRMmFNpm3LhxOHHihK6PICIiogpO56kfheLVQ1QGBgZcx0JERFQEKk79iCrV7TgNGzZEUlJSaT6CiIioXOAaFXHFSlR8fX01fnZzc0PdunW12hkaGqJ27dro1q0bAgMDSxQgERERVVzFSlReXpMiCAJat26N1q1bi7YVBAEXL17E7NmzSxIfERFRhcDtyeKKlajUq1cPQN76lIcPH2LlypVYtWqVVrvc3FwkJCQgPT1dmiiJiIjKOS7pFFesRCUiIkL93xMnTsTVq1c16oiIiIikpPNi2i1btmj8bGVlhSpVquDJkyclDoqIiKii4dSPOJ3PUfmv2bNnIzw8XKruiIiIKhSVoJCslCeSJSpEREREUuNrjYmIiGSA56iIY6JCREQkA9z1I06yREWhUBTpWH0iIiLSVt7WlkhFsjUqCxYsgKGhoVTdEREREXHqh4iISA64RkVckRMVV1dXnR9y+vRpne8lIiKqCLhGRVyRE5WTJ09C0PFX0ciIAzdERERUfEXOIBYuXKiVqHTs2BF9+/bF/fv3cfbsWcTExKBmzZro3LkzGjVqhMOHD+P8+fOSB01ERFTecDGtOAUAnYZJunbtiiNHjuCzzz6Dr6+v1vUpU6Zg1apV6NOnD86ePVvSOEuFobGDvkMgIqLXQG52ZKk/I9jBTbK+2kfuLVZ7Z2dneHt7o2vXrjAzM8PDhw+xceNGrFmzRt2mU6dO+O6779CmTRskJyfD398fnp6eSEtLkyxuMTonKidOnEB8fDyGDRtWYJvdu3fDxsYGvXr10jW+UsVEhYiIiqI8Jyp9+vTBgQMHcPXqVezYsQOpqalwcnKCgYEBvvzySwBAq1at8PfffyM0NBQbN26Eo6Mj5s6dixMnTqBfv36SxS1G58UjLi4uWLVqVaFtQkNDMWPGDF0fQUREVGHoY+rHysoKW7ZsQUBAAIYNG1bgWtQlS5YgISEBPXr0QEpKCgDg0aNH8PHxQZ8+fXDkyJFSi1Hnc1SUSiWcnZ0LbePs7AylUqnrI4iIiCoMQcJSVKNHj4adnR2+/vprCIKASpUqaR3eamVlhT59+uD3339XJykAsGXLFqSkpGDEiBE6fd6i0jlR+euvv/DOO+/gyy+/hLGxscY1Y2NjfPXVV+jbty8OHz5c4iCJiIhIer1790ZSUhJq1aqFO3fuIC0tDcnJyVi7di1MTU0BAC1btoSxsTEuXbqkcW92djZCQkJeOWhRUjpP/Xz++edwdXXF4sWLMXPmTFy6dAmxsbGoUaMG2rZtixo1aiAyMhJffPGFlPESERGVS1JO/ZiYmKgTjXxZWVlasxwNGzaEkZER9u3bB19fX3h4eKBHjx6YMWMGqlSpgtGjR8Pe3h4AEBUVpfWcqKioEp2zVhQ6j6g8e/YMbdu2xW+//QZra2v0798fEydORP/+/WFtbY3ffvsN7dq1w7Nnz6SMl4iIqFwSBIVkxcPDA8nJyRrFw8ND65mWlpawsLDAli1bMHPmTOzZswczZ87E+vXrMWrUKDRo0ADm5uYA8hKd/8rMzFRfLy0lOoktJiYGEydOxJQpU9C4cWNYW1sjKSkJ9+7dQ3Z2tlQxEhERlXsqCftaunQpli9frlEnlmhkZGQAALZv365Rv23bNkybNg2dOnVCeno6AGiN0ACAmZmZuo/SIsmRsTk5Obh165YUXREREVEJKZXKIm1miYyMRIsWLRATE6NRHxsbCwCwsbFBWFgYAKingF5mb2+PyMjS3bot2duTiYiISHcCFJKVorp8+TIAoFatWhr1Dg5554zFxcXh5s2byM7ORtu2bTXaGBsbo3Xr1ggJCSnZB3+FEiUqb731FgICAhAbGwulUomcnBytwikgIiKiV1MJ0pWi8vf3BwBMmjRJo37y5MnIzs7GyZMnkZycjKNHj+KDDz6ApaWlus3YsWNhZWWFnTt3SvL5C6Lz1M+QIUOwY8cOGBgY4PHjx7hz5w5ycnKkjI2IiIhKUUhICHx9fTFp0iQYGRkhKCgIPXr0wIgRI7BkyRL1Tp+vv/4a586dQ1BQkPpk2jlz5uDw4cOlfgyJzkfoh4SEoH79+njvvfdw4sQJicMqGzxCn4iIiqIsjtA/VmO4ZH29FVv0UQ4jIyN4enpi4sSJcHBwwOPHj/Hzzz9rnT7fpUsXfPvtt2jTpg1SUlLg7+8PDw8PpKamSha3GJ0TlYyMDPz222+YOnWqxCGVHSYqRERUFGWRqBytId0Jr71j/SXrS990XqMSHx+v3rJEREREVBp0XqOya9cu9O7dG4aGhsjNzZUyJiIiogpHynNUyhOdR1Q8PT2RmJiIHTt2oHbt2lLGREREVOHoY3vy60DnEZUbN27A2NgYHTt2hJubGxITE5GUlKTVThAENGjQoERBEhERUcWkc6JiYGCAnJwcREREqOv++2roguqIiIhIE6d+xOmcqNSrV0/KOIiIiCo0JiriJHnXDxEREZVMeVtbIhW+64eIiIhkS+cRFV9f3yK1EwQBkydP1vUxREREFYKKAyqidD6Z9lVnpwiCAIVCAUEQYGQkzxkmnkxLRERFURYn0+6tOUqyvtxitkvWl75JvpjW2toabdq0wddff42rV6/iiy++0Dk4IiIiqth0TlRe3pb8Xzdu3EBgYCBu3LiB/v37Y+3atbo+hoiIqELQaXqjAii1xbSxsbE4cOAAPvvss9J6BBERUbmhkrCUJ6W66yclJQV169YtzUcQERFROVZqq1ytra3x3nvvISYmprQeQUREVG6oeJK7KJ0Tlfnz54t3aGSEWrVqYdCgQahatSq8vb11fQQREVGFwTUq4nROVF6VgKSkpGDp0qX45ptvdH0EERERVXA6Jyo9e/YUrVepVEhISMDdu3eRk5Ojc2BEREQVSXlbBCsVnROVU6dOSRkHERFRhcaTacXJ88hYIiKiCkbFlxKKKvH25NGjR+Ovv/5CbGwsMjMzERsbi8OHD2PUKOmOAiYiIqKKSecRFQMDA/j7+8PNzQ0KhQKZmZmIjIxEzZo10bt3b7z11lsYOnQohg8fDkHgWmYiIqLC8G9KcTqPqMyYMQODBw/G2bNn0aVLF1hYWKB+/fqwsLBA586dcebMGbi5uWH69OlSxktERFQuqRTSlfJE57cnX716FWZmZmjZsqXo7h4jIyNcv34dWVlZcHZ2LmmcpYJvTyYioqIoi7cn/+owRrK+xkdulawvfdN5RKVRo0bYv39/gVuQc3JycODAATRq1Ejn4IiIiCoKvutHnM5rVJRKJSwsLAptY2FhAaVSqesjiIiIKgyuURGn84jK1atXMWLECNjb24tet7Ozw4gRI3DlyhWdgyMiIqKKTedEZfny5bC1tcWlS5fg7u4OFxcXODo6wsXFBXPmzMHly5dRtWpVLF++XMp4iYiIyiUuphWn89TPwYMHMXfuXCxbtgzfffedxjWFQoGcnBzMnTsXAQEBJQ6SiIiovCtva0ukUqKTaVesWIG9e/dizJgxaN26NSpXrozk5GRcvXoV27ZtQ3h4uFRxEhERUQWkc6IyduxYxMTE4K+//uIbkomIiEqIIyridF6j4uvri3feeUfKWIiIiCosQSFdKU90HlGJioqCkRHfaUhERCQFjqiI03lEZf/+/ejTpw9MTEykjIeIiIhITedE5euvv0ZaWhr++OMPNGvWTMqYiIiIKhyeTCtO57mbq1evwtTUFK1bt8Y777yDzMxMxMbGar0pWRAENGjQoMSBEhERlWc8mVaczomKgYEBlEolIiIiNOoVCkWhPxMREREVlc6JSr169aSMg4iIqEIrbyfKSoXbdoiIiGSgvK0tkYrOiYqvr+8r26hUKiQnJ+Pu3bs4ePAgIiMjdX0cERERVUAK6Lh+Jzc3V71wVmwdiiAIGvU5OTlYuHAhFi9erFukpcDQ2EHfIRAR0WsgN7v0/6H9Q+0xkvU198lWyfrSN523Jzs5OeHgwYOIjY2Fp6cnunfvjiZNmqB79+7w9PRETEwM9u/fjw4dOmDq1KmIjIzEggULMGLECCnjJyIiKhcECUt5ovPUz8iRI9GhQwe0atUKsbGx6vr79+/jzJkz8PPzQ0hICHr27Invv/8egYGBuH37Nj755BP4+/tLEjwRERGVbzqPqEyaNAn+/v4aScrLYmJisHPnTkyZMgUAEBkZiYMHD6JVq1a6PpKIiKjcUimkK+WJziMqjo6OyMrKKrRNZmYmHB0d1T9HRETAzMxM10cSERGVW9z1I07nEZVnz57Bzc0NpqamotdNTU3h5uaGZ8+eqetq1KiBhISEAvts2bIlKleurGtIREREry2uURGnc6Li6+sLJycnnDlzBgMHDkTVqlUBAFWrVsXAgQNx5swZ1K9fH7/88ov6HldXV1y7dq3APq9evYr+/furfz527Bh69eqla4hERERUTJ6enhAEATdu3NC61qlTJ5w+fRppaWmIiorCqlWrYGFhUarx6Dz1891336Fp06b44IMPsGfPHgB556YYGOTlPgqFAtu2bcOyZcsA5I2mBAQE4NChQwX2mZGRgUqVKql/7tGjB3x8fHQNkYiI6LWhksFYSK1ateDp6YnU1FSta61atcKxY8cQGhoKd3d3ODo6Yu7cuWjYsCH69etXajHpnKioVCqMHz8efn5+GDt2LN58801UrlwZycnJuHbtGrZu3Yrjx4+r28fGxsLd3b3QPq9duwZ3d3fk5uYiKSkJANCuXTtkZmYWel9+okRERPS6ksMalR9++AHnz5+HoaEhqlWrpnFtyZIlSEhIQI8ePZCSkgIAePToEXx8fNCnTx8cOXKkVGLS+cC30uDi4oJdu3bhjTfeAKB9aJwYQRBgZKRbvsUD34iIqCjK4sC3hW+Mlqyv/4vYVux7XF1dcfz4cTg7O2PNmjWoVq0aWrZsCQCwsrJCfHw8VqxYgS+//FJ9j7GxMeLj47Fjxw71Ll+pyepdP5cvX0aDBg3g5OSEmjVr4uTJk1i8eDGOHj2q79CIiIhKlT5HDQwMDLBmzRr4+Pjg5s2bWtdbtmwJY2NjXLp0SaM+OzsbISEhcHZ2LrXYZJWoAHlH89+7dw/37t3Dr7/+ioMHDyI4OFjfYREREZUqKad+TExMtHblZmVlQalUirafNm0a6tSpg969e4tet7e3BwBERUVpXYuKioKrq2sJIy6Yzrt+ysKHH36okaRUrlxZvViXiIiIxHl4eCA5OVmjeHh4iLatWrUqFi5ciEWLFuH58+eibczNzQFA9Py0zMxM9fXSIPu/9V1cXBAYGIi0tDTEx8eje/fuAABbW1vs3btX/TMREdHrTMqTaZcuXYrKlStrlKVLl4o+95tvvsGLFy+wZs2aAmPLyMgAANGz08zMzNTXS4OsE5VOnTrhzJkzaNiwIX7//XeN0ZT4+HhYW1vjo48+0mOERERE0lBBkKwolUqkpKRoFLFpnwYNGmDq1KlYvXo1HBwcUKdOHdSpUwdmZmYwNjZGnTp1YGNjo57yyZ8Cepm9vT0iI0tvsbGsE5UlS5YgNDQUzZo1g6enp9b1EydOoEOHDnqIjIiI6PVXq1YtGBoaYs2aNXj06JG6dOzYEY0bN8ajR4/wf//3f7h58yays7PRtm1bjfuNjY3RunVrhISElFqMsltM+7J27drBw8MDSqUSgqC9HvrZs2ews7PTQ2RERETS0seun5s3b8LNzU2r/ptvvoGVlRVmzpyJsLAwJCcn4+jRo/jggw+waNEi9YFwY8eOhZWVFXbu3FlqMco6UcnOzi508WytWrVET88jIiJ63ejjwLf4+Hjs27dPq37WrFkAoHHt66+/xrlz5xAUFISNGzfC0dERc+bMweHDh3H48OFSi1HWUz/nz5/HsGHDRK9VqlQJEydORFBQUBlHRUREJD0p16iUhqtXr6J3797IyMjAihUrMHXqVPj6+hb497RUZD2i4uXlhaCgIBw8eBDbt28HkPeugfr162Pu3LmoXr06Fi1apOcoiYiIypeePXuK1p89exZdu3Yt01hkdYS+mJ49e2LdunVo2LChRn1YWBgmT56MU6dO6dw3j9AnIqKiKIsj9D+v875kfX3/+H+S9aVvsh5RsbKywrlz59CkSRO0atUKDRs2hIGBAcLCwnD58mV9h0dERCQZObyUUI5km6iYmJjgxYsX8PT0xPfff49r167h2rVr+g6LiIiIypBsExWlUono6GjR43qJiIjKm9JaBPu6k/WuHz8/P4wbNw7Gxsb6DoWIiKhUCRKW8kS2IyoAcOPGDbi5ueHWrVvw8/PDo0ePRN8nsGfPHj1ER0RERKVN1rt+cnNzX9lGEAQYGemWb3HXDxERFUVZ7PqZUWekZH2tfrxDsr70TdYjKgXt4yYiIipvBPmOG+iVrBOVkpyRQkRE9Drh9mRxsk5UXta0aVPUqVMHAPD48WOEhobqOSIiIiIqbbJPVAYNGoTly5ejbt26GvXh4eFwd3fHgQMH9BMYERGRhLg9WZystye/++672L17NwDA09MTgwcPxuDBg+Hp6QmFQoE//vgDffv21XOUZGJigqVLPBHx6DJSkh7g3JkD6P2Wa5HudXCww/Zt6/E89jZePL+DP3b/gnr13hBtO3HC+7hx/SRSk8MQeusMPv1kopQfg0hy/G5QcXB7sjhZ7/o5d+4cTE1N4erqivT0dI1rlSpVwpkzZ5CZmYnOnTvr1D93/Ujj999+xtAh/bF6tQ/uPwjH+HEj0LZtK/TuMxxnz10s8D4Li0q4GHwY1pWtsGLlBmRn52DmjClQKBRwafc2XrxIULedMvkDrFv7LXb/EYC//jqJrl07YOwHw+DhuRjf/7C2LD4mUbHxu1F+lMWun2l1hkvW1/rHOyXrS99knaikpqbC09MTq1evFr0+Y8YMLFmyBJaWljr1z0Sl5Nq1bY2/zwXgiy8XYvmKDQAAU1NTXLt6DHFx8XDt/l6B986d8zGWLZ2Hjp364dLlvNcjNG7shGtXj+OHH9dh3vxlAAAzMzM8engRFy5cwXuDx6vv/9VvNd4b9A7q1m+HxMSkUvyURMXH70b5UhaJytQ6wyTra+PjXZL1pW+ynvrJzMxE1apVC7xetWpVZGZmlmFE9F9Dh/ZHTk4ONvlsVddlZWVhs9//0KlTWzg6FpwMDh3SHxcvXlX/QQwAd++G4fjxMxg2dIC6rmePzqhWrSrWb/hV4/51636FpaUF+vV7S8JPRCQNfjeouFQSlvJE1onK8ePHMXPmTHTs2FHrWvv27TFjxgwcPXpUD5FRvtatWuDe/YdISUnVqL94MeSf681F71MoFGjZsikuXb6ude3ipRA0aFAPlpYWeX20bgEAGn9oA8DlK9eRm5sL51YtSvoxiCTH7waRNGS96+eLL77A33//jTNnziA4OBh3794FADRu3Bjt27dHbGwsvvzySz1HWbHZ2ddAdFSsVn1UdAwAwN6+puh9VatWgZmZGaKjRe79pz8HBzvcuxcGO7sayMnJQVxcvEa77OxsxMcnwN5B/BlE+sTvBhUXD3wTJ+sRlUePHuHNN9/E6tWrYWNjg5EjR2LkyJGwsbHBqlWr0KpVKzx+/FjfYVZo5mZmom+4zszMqzM3NxO/z9wcAAq4N1PjXnNzMyiV2aL9ZGZmFfgMIn3id4OKi1M/4mQ9ogIAcXFxcHd3h7u7e4n6MTExgampqUZdjsoESqWyRP1WdBmZmVq/rgBgZpZXl5EhvoYo/+WS4veaadybkZEJExPxN2ibmZkW+AwifeJ3g0gash5RMTQ0hJWVVYHXraysYGhoWKS+PDw8kJycrFG++vIzqUKtsKKjYmFnX0Or3t4ub8g5KipG9L4XLxKRmZkJOzuRe//pLzIyOu8Z0bEwMjJC9eq2Gu2MjY1ha2uDqEjxZxDpE78bVFyChP8rT2SdqKxevRrnzp0r8PrZs2fx448/FqmvpUuXonLlyhpl2bc/SRVqhXXt2i00algfVlaaW8Tbt3cGAIRcuyV6nyAIuHHzDtq6vKl1rX07Z4SFPUJqapr6GQDQ1qWVRru2Lq1gaGiIkOvizyDSJ343qLg49SNO1onKO++8g127Ct4LvmvXLvTr169IfSmVSqSkpGgUTvuU3O4/AmBkZIQpk8eo60xMTDB+3EhcuHAFT5/mnT1Qu7YDGjd20rj3jz8C0K6dM1za/PsHcqNGTujZswt2/3FQXXf8xFnExyfgo4/Gadz/0UfjkJaWjj//PFYaH42oRPjdoOJSCYJkpTyR9RoVBwcHPHv2rMDrkZGRqFWrVhlGRP8VfPEqdu46gMXfeKBGjWp48OARxo0djrp1HTH1oznqdn6/rEL37p1hZPLv/1/r1v+KSR+Oxv59W7B8xXpkZ+dg1sypiImJUx+QBeQtIPTy/h4/rVmC/23foD5984MxQzFv/jIkJCSW5UcmKhJ+N4ikIetEJT4+Ho0bNy7wetOmTZGcnFyGEZGYCRNnYqH35xgzeihsbKxx40Yo3nMbj9NnLhR6X2pqGt7qMxw//uANT4+ZMDAwQNCpvzFnrjeeP3+h0Xb9hl+RnZ2N2bM/wsABffDkSSTc53hh9Rqf0vxoRCXC7wYVR/kaB5GOrI/Q9/HxwYgRI9CtWzeEhIRoXHN2dsapU6ewc+dOfPjhhzr1zyP0iYioKMriCP1Rb7hJ1tf2iL2S9aVvsk5U7O3tcfHiRdSoUQP79+/HrVt5C8NatGiBgQMHIjY2Fh06dCh0eqgwTFSIiKgomKjoj6ynfqKiotC2bVssW7YM7733HgYPHgwASE5OxtatW+Hp6YmoqCg9R0lERFRy5W1bsVRknagAQHR0NCZMmAAAqF69OoC8Q+DEKBQKODo6Ijo6GtnZ4qc1EhERyVF521YsFVlvT/6vuLi4ApMUIC+RCQ8PR9euXcswKiIiIiotsh9RKS6FQqHvEIiIiIpNxakfUeUuUSEiInodcY2KuNdq6oeIiIgqFo6oEBERyQAX04pjokJERCQDQjl7R49UmKgQERHJABfTiuMaFSIiIpKtcjWikpqaigULFuDhw4f6DoWIiKhYuEZF3GuRqHTr1g39+/dHnTp1AACPHz9GQEAATp06pdEuPT0dCxcu1EeIREREJcLtyeJknagYGxtj+/btcHNzg0KhQGJiIgCgSpUqmDNnDvbs2YNRo0YhJydHv4ESERFRqZD1GhUvLy8MHjwYP/74I+zt7WFrawtbW1vY2dnhhx9+wJAhQ/B///d/+g6TiIioxFQQJCvliQKQ7yd6+PAhTp48iQ8//FD0+ubNm9GjRw/Uq1dPp/4NjR1KEh4REVUQudmRpf6MdxzfkayvQ08PSdaXvsl6RMXe3h4XLlwo8PqFCxdgZ2dXhhERERFRWZJ1ovL06VP06NGjwOvdu3fH06dPyy4gIiKiUqKSsJQnsk5Ufv31V4wYMQLr1q1Do0aNYGBgAIVCgUaNGmHt2rUYPnw4/Pz89B0mERFRiQkS/q88kfUaFQMDA/j6+mLcuHEQBAEqlUpdr1Ao8Ouvv2LSpEk6HzvMNSpERFQUZbFGpY9jX8n6OvL0sGR96ZusE5V8b775Jvr164c33ngDQN45Kn/++Sdu3LhRon6ZqBARUVGURaLyluPbkvV17OlfkvWlb7I+RyXf9evXERYWBhsbGygUCnV97dq1AQBPnjzRV2hERESS0NdLCdu2bYvx48ejZ8+eqFu3LuLj43H+/HnMmzcP9+/f12jbpEkTrFixAl27doVSqURAQADc3d3x/PnzUotP1omKqakpvLy8MGnSJNja2hbYzshI1h+DiIjolfR1/smXX36JLl26YOfOnbh+/Trs7Ozw2Wef4cqVK+jYsSNu3boFAKhVqxZOnTqFpKQkeHp6wtLSEnPnzkXLli3Rvn17ZGdnl0p8sv4bfu3atRg/fjz27t2L06dPIyEhQd8hERERlSvLly/H6NGjNRKNHTt24MaNG/jqq68wduxYAICnpycsLCzg4uKinskIDg7G0aNHMWHCBGzatKlU4pP1GpWEhATs2LED06ZNK5X+uUaFiIiKoizWqHSv9ZZkfQU9O1biPi5dugQgb2oIAKKjoxEUFISRI0dqtLtz5w6ePHmCPn36lPiZYmQ9oiIIAq5cuaLvMIiIiEqdSsI1KiYmJjA1NdWoy8rKglKpLHIfNWvWVE/7ODg4oGbNmurk5WXBwcHo169fyQIuhKzPUdm3bx969+6t7zCIiIheKx4eHkhOTtYoHh4eRb5/zJgxcHR0xI4dOwDknRQPAFFRUVpto6KiYGtrCxMTE2mC/w9Zj6gsWrQI/v7+2LBhAzZs2ICIiAjk5uZqtePaFSIiet1JuQ5j6dKlWL58uUZdVlZWke5t3Lgxfv75Z5w7dw6//vorAMDc3LzAPjIzM9VtijNiU1SyTlTyt0U5Oztj0qRJBbbjrh8iInrdSbnrR6lU6pQ01KxZEwEBAUhKSsKwYcPUB61mZGQAgNZ0EgCYmZlptJGarP+GX7hwod72lRMREVUklStXRmBgIKpUqQJXV1eNaZ78/86fAnqZvb094uPjS2U0BZB5orJgwQJ9h0BERFQm9HWOCpA3UnLgwAE0atQIvXv3RmhoqMb1yMhIxMbGqncAvax9+/YICQkptdhkvZiWiIioohAEQbJSHAYGBtixYwc6deqE4cOH4/z586Ltdu/ejQEDBsDR0VFd16tXLzRu3Bg7d+4s0WcvjKzPUSltPEeFiIiKoizOUelg312yvi5EBRW57YoVKzBr1izs378f/v7+Wte3bt0KAHB0dMTVq1eRmJiIVatWwdLSEp9//jmePn2Kdu3aldrUDxMVIiKiVyiLRKWdfTfJ+roYdarIbU+cOIEePXoUeP3ld+w1a9YMy5cv13jXz5w5cxAbG1uScAvFRIWIiOgVyiJRaWvvKllfl6JOS9aXvsl6MS0REVFFwV2u4riYloiIiGSLIypEREQyoM/tyXLGRIWIiEgGOPUjjlM/REREJFscUSEiIpIBTv2IY6JCREQkAwITFVGc+iEiIiLZ4ogKERGRDKi4mFYUExUiIiIZ4NSPOE79EBERkWxxRIWIiEgGOPUjjokKERGRDHDqRxwTFSIiIhngiIo4rlEhIiIi2eKIChERkQxw6kccExUiIiIZ4NSPOE79EBERkWxxRIWIiEgGOPUjjokKERGRDAiCSt8hyBKnfoiIiEi2OKJCREQkAypO/YhiokJERCQDAnf9iOLUDxEREckWR1SIiIhkgFM/4pioEBERyQCnfsQxUSEiIpIBnkwrjmtUiIiISLY4okJERCQDPJlWHBMVIiIiGeAaFXGc+iEiIiLZ4ogKERGRDHB7sjgmKkRERDLAqR9xnPohIiIi2eKIChERkQzwHBVxTFSIiIhkgFM/4jj1Q0RERLLFERUiIiIZ4K4fcUxUiIiIZIBTP+KYqBAREckAF9OK4xoVIiIiki2OqBAREckAX0oojokKERGRDHDqRxynfoiIiEi2OKJCREQkA9z1I44jKkRERDIgSPi/4jAxMcGyZcvw7NkzpKen4/z58+jdu3cpfcriY6JCRERUgfn5+cHd3R1bt27FzJkzkZubiz///BNdunTRd2gAAAVQcZcZGxo76DsEIiJ6DeRmR5b6M4xNaknWV7byWZHatWvXDsHBwZg7dy5+/PFHAICpqSlu3ryJ2NhYWSQrHFEhIiKSAUEQJCtFNWzYMOTk5GDjxo3quqysLPj6+qJz585wdHQsjY9aLExUiIiIKihnZ2fcu3cPKSkpGvXBwcEAgNatW+shKk3c9UNERCQDUq7DMDExgampqUZdVlYWlEqlRp29vT2ioqK07s+vc3DQ/xKJCp2olMWcIxERUVFI+XfSPC8veHt7a9R5e3tjwYIFGnXm5ubIysrSuj8zM1N9Xd8qdKJCRERUHi1duhTLly/XqBNLSDIyMrRGXgDAzMxMfV3fmKgQERGVM0qlUmuaR0xUVBRq1dLebWRvbw8AiIzU/8wDF9MSERFVUCEhIWjUqBGsrKw06jt06KC+rm9MVIiIiCqoXbt2wcjICFOnTlXXmZiYYOLEiTh//jyePn2qx+jycOqHiIioggoODoa/vz+WLl2KGjVq4MGDBxg/fjzq1q2LSZMm6Ts8NYGFhYWFhYWlYhZTU1Phu+++EyIjI4WMjAzhwoULwttvv633uPJLhT5Cn4iIiOSNa1SIiIhItpioEBERkWwxUSEiIiLZYqJCREREssVEhYiIiGSLiQoRERHJFhMVIiIiki0mKkRERCRbTFSIiIhItpioEBERkWwxUSEiIiLZYqJCREREssVEhYiIiGTr/wEl+U7QyqdMVwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure() #this creates a new figure on which your plot will appear\n",
    "plt.tight_layout()\n",
    "\n",
    "ax = sns.heatmap(confusion_arr, xticklabels=[\"has_coref\", \"no_coref\"], yticklabels=[\"has_coref\", \"no_coref\"], annot=True, fmt='.2f')\n",
    "\n",
    "ax.set_xlabel('predict')\n",
    "ax.set_ylabel('ground-truth')\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoNLL F1 Score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only TP (42 doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../output/mimic_cxr/coref/individual_conll_ground_truth/findings/s54739969.conll'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m doc_id \u001b[39min\u001b[39;00m true_positive[section_name]:\n\u001b[1;32m      7\u001b[0m     \u001b[39m# gt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     input_conll_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39m../../output/mimic_cxr/coref/individual_conll_ground_truth\u001b[39m\u001b[39m\"\u001b[39m, section_name, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdoc_id\u001b[39m}\u001b[39;00m\u001b[39m.conll\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     copy_and_paste_conll(input_conll_file, output_conll_file_gt)\n\u001b[1;32m     10\u001b[0m     \u001b[39m# pred\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     input_conll_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39m../../output/mimic_cxr/coref/individual_conll\u001b[39m\u001b[39m\"\u001b[39m, section_name, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdoc_id\u001b[39m}\u001b[39;00m\u001b[39m.conll\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/PhD/workspace/VSCode_workspace/sr_coref/src/coreference_resolution/../../src/coreference_resolution/data_preprocessing/mimic_cxr_csv2conll.py:171\u001b[0m, in \u001b[0;36mcopy_and_paste_conll\u001b[0;34m(input_conll_file, output_conll_file)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcopy_and_paste_conll\u001b[39m(input_conll_file, output_conll_file):\n\u001b[0;32m--> 171\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(input_conll_file, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mUTF-8\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f_in, \u001b[39mopen\u001b[39m(output_conll_file, \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUTF-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f_out:\n\u001b[1;32m    172\u001b[0m         f_out\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(f_in\u001b[39m.\u001b[39mreadlines()))\n\u001b[1;32m    173\u001b[0m         f_out\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../output/mimic_cxr/coref/individual_conll_ground_truth/findings/s54739969.conll'"
     ]
    }
   ],
   "source": [
    "output_conll_file_gt = os.path.join(output_dir, \"gt_42_noWhich.conll\")\n",
    "output_conll_file_pred = os.path.join(output_dir, \"pred_42.conll\")\n",
    "check_and_remove_file(output_conll_file_gt)\n",
    "check_and_remove_file(output_conll_file_pred)\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    for doc_id in true_positive[section_name]:\n",
    "        # gt\n",
    "        input_conll_file = os.path.join(\"../../output/mimic_cxr/coref/individual_conll_ground_truth\", section_name, f\"{doc_id}.conll\")\n",
    "        copy_and_paste_conll(input_conll_file, output_conll_file_gt)\n",
    "        # pred\n",
    "        input_conll_file = os.path.join(\"../../output/mimic_cxr/coref/individual_conll\", section_name, f\"{doc_id}.conll\")\n",
    "        copy_and_paste_conll(input_conll_file, output_conll_file_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_conll_score(output_conll_file_gt, output_conll_file_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TP + FP (42+2), which is the ensemble application scenario\n",
    "\n",
    "gt_44 (tp) + pred_44 (tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_conll_file_gt = os.path.join(output_dir, \"gt_44_noWhich.conll\")\n",
    "check_and_remove_file(output_conll_file_gt)\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = list(true_positive[section_name]) # false_positive files are not existing here, thus ignore\n",
    "    for doc_id in doc_list:\n",
    "        input_conll_file = os.path.join(\"../../output/mimic_cxr/coref/individual_conll_ground_truth\", section_name, f\"{doc_id}.conll\")\n",
    "        copy_and_paste_conll(input_conll_file, output_conll_file_gt)\n",
    "\n",
    "output_conll_file_pred = os.path.join(output_dir, \"pred_44.conll\")\n",
    "check_and_remove_file(output_conll_file_pred)\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = list(true_positive[section_name]) + list(false_positive[section_name])\n",
    "    for doc_id in doc_list:\n",
    "        input_conll_file = os.path.join(\"../../output/mimic_cxr/coref/individual_conll\", section_name, f\"{doc_id}.conll\")\n",
    "        copy_and_paste_conll(input_conll_file, output_conll_file_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_conll_score(output_conll_file_gt, output_conll_file_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 100x: all (200), which is the actural conll scoring scenario.\n",
    "\n",
    "1. Step 1: get fast_coref_xxx model outputs (csv files in /nlp_ensemble/temp_for_eval), then\n",
    "2. Step 2: get majority_voting pipeline outputs (csv files in /coref_voting/temp_for_eval), then\n",
    "3. Step 3: accordingly generate conll file and do evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Need to generate /nlp_ensemble/fast_coref_xxx csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model: ../../../../git_clone_repos/fast-coref/models/coref_model_7a03/best and doc_encoder: /home/yuxiangliao/PhD/workspace/git_clone_repos/fast-coref/models/longformer_coreference_joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuxiangliao/anaconda3/envs/sr_coref/lib/python3.9/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "100%|██████████| 100/100 [01:55<00:00,  1.16s/it]\n",
      "100%|██████████| 100/100 [01:56<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"../../../../git_clone_repos/fast-coref/src\")\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from nlp_ensemble.nlp_menbers import play_fastcoref\n",
    "from inference.tokenize_doc import tokenize_and_segment_doc\n",
    "from nlp_ensemble.nlp_menbers.play_fastcoref import inference, resolve_output\n",
    "from common_utils.nlp_utils import align_byIndex_individually_nestedgruop, align_coref_groups_in_conll_format\n",
    "\n",
    "config = None\n",
    "with initialize(version_base=None, config_path=\"../config\", job_name=\"nlp_ensemble\"):\n",
    "        config = compose(config_name=\"nlp_ensemble\", overrides=[\"+nlp_ensemble@_global_=mimic_cxr\"])\n",
    "\n",
    "# Init model\n",
    "### Modify ###\n",
    "model_dir = \"../../../../git_clone_repos/fast-coref/models/coref_model_7a03/best\"\n",
    "config.fastcoref_joint.output_dir = \"../../output/mimic_cxr/nlp_ensemble/temp_for_eval/fast_coref_7a03\"\n",
    "\n",
    "config.fastcoref_joint.model_dir = os.path.join(model_dir,\"best\") if os.path.exists(os.path.join(model_dir,\"best\")) else model_dir\n",
    "model, subword_tokenizer, max_segment_len = play_fastcoref.init_coref_model(config)\n",
    "\n",
    "\n",
    "spacy_nametyle = config.name_style.spacy.column_name\n",
    "fastcoref_joint_nametyle = config.name_style.fastcoref_joint.column_name\n",
    "\n",
    "# output_conll_file_pred = os.path.join(output_dir, \"pred_joint_best.conll\")\n",
    "# check_and_remove_file(output_conll_file_pred)\n",
    "\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = gt_dict_allDoc[section_name]\n",
    "    for doc_id in tqdm(doc_list):\n",
    "        spacy_csv_file = os.path.join(\"../../output/mimic_cxr/nlp_ensemble/spacy\", section_name, f\"{doc_id}.csv\")\n",
    "        # Load preprocessed tokens from csv files.\n",
    "        df_base = pd.read_csv(spacy_csv_file, index_col=0)\n",
    "        sent_tok_2d_list, tok_indices_in_spacy = format_input_tok_same_as_traingset(df_base, spacy_nametyle)\n",
    "\n",
    "        # Using longformer tokenizer to generate subtokens and form the input data.\n",
    "        tokenized_doc = tokenize_and_segment_doc(sent_tok_2d_list, subword_tokenizer, max_segment_len=max_segment_len)\n",
    "\n",
    "        # Get model output\n",
    "        pred_mentions, mention_scores, gt_actions, pred_actions = inference(model, tokenized_doc)\n",
    "\n",
    "        # Resolve model output\n",
    "        coref_group_list = resolve_output(tokenized_doc, pred_mentions, pred_actions, ignore_singleton = True)\n",
    "        \n",
    "        # To dataframe\n",
    "        spacy_tok_list = df_base.loc[:, spacy_nametyle.token].to_list()\n",
    "        spacy_sentGroup_list = df_base.loc[:, spacy_nametyle.sentence_group].to_list()\n",
    "        input_tok_list = [tok for sent in sent_tok_2d_list for tok in sent]\n",
    "        \n",
    "        coref_group_aligned_to_input_tok = align_byIndex_individually_nestedgruop(len(input_tok_list), coref_group_list)\n",
    "        coref_group_aligned_to_spacy_tok = align_to_spacy(tok_indices_in_spacy, coref_group_aligned_to_input_tok, input_tok_list, spacy_tok_list)\n",
    "\n",
    "        coref_group_conll_aligned_to_input_tok = align_coref_groups_in_conll_format(len(input_tok_list), coref_group_list)\n",
    "        coref_group_conll_aligned_to_spacy_tok = align_to_spacy(tok_indices_in_spacy, coref_group_conll_aligned_to_input_tok, input_tok_list, spacy_tok_list)\n",
    "        \n",
    "        df_fastcoref_joint = pd.DataFrame(\n",
    "            {\n",
    "                fastcoref_joint_nametyle[\"token_from_spacy\"]: [str(i) for i in spacy_tok_list],\n",
    "                fastcoref_joint_nametyle[\"sentence_group\"]: [int(i) for i in spacy_sentGroup_list],\n",
    "                fastcoref_joint_nametyle[\"coref_group\"]: [str(i) for i in coref_group_aligned_to_spacy_tok],\n",
    "                fastcoref_joint_nametyle[\"coref_group_conll\"]: [str(i) for i in coref_group_conll_aligned_to_spacy_tok],\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Overwrite csv\n",
    "        csv_output_dir = os.path.join(config.fastcoref_joint.output_dir, section_name)\n",
    "        check_and_create_dirs(csv_output_dir)\n",
    "        df_fastcoref_joint.to_csv(os.path.join(csv_output_dir, doc_id+\".csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Need to generate majority_voting gt (csv) files when only have fast_coref_xxx outputs (csv)\n",
    "\n",
    "modify /config/coreference_resolution/coref_voting/mimic_cxr.yaml -> ${input.in_use}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.66it/s]\n",
      "100%|██████████| 100/100 [00:17<00:00,  5.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from common_utils.coref_utils import shuffle_list\n",
    "import coref_voting\n",
    "from coref_voting import DocClass, MentionClass, compute_voting_result, get_output_df\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from nlp_ensemble.nlp_menbers import play_fastcoref\n",
    "\n",
    "\n",
    "config = None\n",
    "with initialize(version_base=None, config_path=\"../config\", job_name=\"majority_voting\"):\n",
    "        config = compose(config_name=\"coreference_resolution\", overrides=[\"+coreference_resolution/coref_voting@_global_=mimic_cxr\"])\n",
    "\n",
    "### Modify. Also check /config/coreference_resolution/coref_voting/mimic_cxr.yaml -> ${input.in_use} ###\n",
    "config.input.source.in_use = [\"rb\",\"fj\",\"gt\"] # ml, rb, fj, gt, fj_x, fj_x2\n",
    "config.input.source.coref_models.fj_x.dir = \"../../output/mimic_cxr/nlp_ensemble/temp_for_eval/fast_model_7a03\"\n",
    "config.input.source.coref_models.fj_x2.dir = \"../../output/mimic_cxr/nlp_ensemble/temp_for_eval/fast_coref_best\"\n",
    "config.input.source.coref_models.gt.dir = \"../../output/mimic_cxr/manual_test_set/round1x2_new\"\n",
    "mv_output_base_dir = os.path.join(\"../../output/mimic_cxr/coref_voting/temp_for_eval/rb_fj_gtnew\")\n",
    "\n",
    "def do_majority_voting(config, spacy_file_path, section_name, file_name):\n",
    "    \"\"\" Voting on one document \"\"\"\n",
    "\n",
    "    START_EVENT.wait()\n",
    "\n",
    "    # Read spacy output as alignment base\n",
    "    df_spacy = pd.read_csv(spacy_file_path, index_col=0, na_filter=False)\n",
    "    # Some of the i2b2 raw files are utf-8 start with DOM, but we didn't remove the DOM character, thus we fix it here.\n",
    "    df_spacy.iloc[0] = df_spacy.iloc[0].apply(lambda x: x.replace(\"\\ufeff\", \"\").replace(\"\\xef\\xbb\\xbf\", \"\") if isinstance(x, str) else x)\n",
    "\n",
    "    docObj: DocClass = coref_voting.resolve_voting_info(config, df_spacy, section_name, file_name)\n",
    "    valid_mention_group: list[set[MentionClass]] = compute_voting_result(config, docObj)\n",
    "    df_out = get_output_df(config, df_spacy, valid_mention_group, docObj)\n",
    "\n",
    "    mv_output_dir = os.path.join(mv_output_base_dir, section_name)\n",
    "    check_and_create_dirs(mv_output_dir)\n",
    "    output_file_path = os.path.join(mv_output_dir, file_name)\n",
    "\n",
    "    df_out.to_csv(output_file_path)\n",
    "\n",
    "    return f\"{file_name} done.\"\n",
    "\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    with ProcessPoolExecutor(max_workers=config.thread.workers) as executor:\n",
    "        all_task = []\n",
    "        doc_list = gt_dict_allDoc[section_name]\n",
    "        for doc_id in doc_list:\n",
    "            file_name = doc_id + \".csv\"\n",
    "            spacy_out_dir = os.path.join(config.input.source.baseline_model.dir, section_name)\n",
    "            spacy_file_path = os.path.join(spacy_out_dir, file_name)\n",
    "            all_task.append(executor.submit(do_majority_voting, config, spacy_file_path, section_name, file_name))\n",
    "        \n",
    "         # Notify tasks to start\n",
    "        START_EVENT.set()\n",
    "\n",
    "        if all_task:\n",
    "            for future in tqdm(as_completed(all_task), total=len(all_task)):\n",
    "                msg = future.result()\n",
    "\n",
    "        executor.shutdown(wait=True, cancel_futures=False)\n",
    "        START_EVENT.clear()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Have majority_voting gt files already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt: ../../resources/eval/gt_200_noWhich_new.conll\n",
      "pred: ../../resources/eval/pred_mv.conll\n",
      "Metric: muc\n",
      "mention_recall, mention_precision, mention_f1: 61.34, 94.55, 74.41\n",
      "coref_recall, coref_precision, coref_f1: 58.87, 90.86, 71.45\n",
      "Metric: bcub\n",
      "mention_recall, mention_precision, mention_f1: 61.34, 94.55, 74.41\n",
      "coref_recall, coref_precision, coref_f1: 58.76, 92.22, 71.79\n",
      "Metric: ceafe\n",
      "mention_recall, mention_precision, mention_f1: 61.34, 94.55, 74.41\n",
      "coref_recall, coref_precision, coref_f1: 60.41, 92.99, 73.24\n",
      "Overall F1: 72.16000000000001\n"
     ]
    }
   ],
   "source": [
    "### Modify ###\n",
    "mv_output_base_dir = os.path.join(\"../../output/mimic_cxr/coref_voting/temp_for_eval/rb_fj_gtnew\")\n",
    "\n",
    "output_conll_file_pred = os.path.join(output_dir, \"pred_mv.conll\")\n",
    "check_and_remove_file(output_conll_file_pred)\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = gt_dict_allDoc[section_name]\n",
    "    for doc_id in doc_list:\n",
    "        input_csv_file = os.path.join(mv_output_base_dir, section_name, f\"{doc_id}.csv\")\n",
    "        from_csv_to_conll(section_name, doc_id, output_conll_file_pred, input_csv_file, \"[mv]coref_group_conll\", \"[sp]sentence_group\",\"[sp]token\")\n",
    "\n",
    "output_conll_file_gt = os.path.join(output_dir, \"gt_200_noWhich_new.conll\")\n",
    "compute_conll_score(output_conll_file_gt, output_conll_file_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1-2: scoref, dcoref, fast_coref_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from nlp_ensemble.nlp_menbers import play_fastcoref\n",
    "\n",
    "config = None\n",
    "with initialize(version_base=None, config_path=\"../config\", job_name=\"statistic\"):\n",
    "        config = compose(config_name=\"nlp_ensemble\", overrides=[\"+statistic/coref_scoring@_global_=mimic_cxr\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common way for testing scoref, dcoref, fast_coref_joint\n",
    "\n",
    "scoref:(ml)\n",
    "Metric: muc\n",
    "mention_recall, mention_precision, mention_f1: 50.58, 70.32, 58.84\n",
    "coref_recall, coref_precision, coref_f1: 42.67, 58.05, 49.19\n",
    "Metric: bcub\n",
    "mention_recall, mention_precision, mention_f1: 50.58, 70.32, 58.84\n",
    "coref_recall, coref_precision, coref_f1: 44.61, 61.07, 51.56\n",
    "Metric: ceafe\n",
    "mention_recall, mention_precision, mention_f1: 50.58, 70.32, 58.84\n",
    "coref_recall, coref_precision, coref_f1: 46.0, 65.65, 54.1\n",
    "Overall F1: 51.61666666666667\n",
    "\n",
    "dcoref (rb)\n",
    "Metric: muc\n",
    "mention_recall, mention_precision, mention_f1: 49.57, 59.95, 54.27\n",
    "coref_recall, coref_precision, coref_f1: 38.31, 46.76, 42.12\n",
    "Metric: bcub\n",
    "mention_recall, mention_precision, mention_f1: 49.57, 59.95, 54.27\n",
    "coref_recall, coref_precision, coref_f1: 41.24, 52.13, 46.05\n",
    "Metric: ceafe\n",
    "mention_recall, mention_precision, mention_f1: 49.57, 59.95, 54.27\n",
    "coref_recall, coref_precision, coref_f1: 47.62, 56.98, 51.88\n",
    "Overall F1: 46.68333333333333\n",
    "\n",
    "fast_coref_joint:\n",
    "Metric: muc\n",
    "mention_recall, mention_precision, mention_f1: 61.17, 78.44, 68.74\n",
    "coref_recall, coref_precision, coref_f1: 54.51, 70.0, 61.29\n",
    "Metric: bcub\n",
    "mention_recall, mention_precision, mention_f1: 61.17, 78.44, 68.74\n",
    "coref_recall, coref_precision, coref_f1: 56.41, 72.82, 63.57\n",
    "Metric: ceafe\n",
    "mention_recall, mention_precision, mention_f1: 61.17, 78.44, 68.74\n",
    "coref_recall, coref_precision, coref_f1: 59.96, 76.77, 67.33\n",
    "Overall F1: 64.06333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:36<00:00,  2.74it/s]\n",
      "100%|██████████| 100/100 [00:33<00:00,  2.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from common_utils.coref_socring import align_spacy_to_ground_truth, align_to_spacy, convert_non_spacy_token_csv_to_conll_format, convert_spacy_token_csv_to_conll_format, find_cloest_index\n",
    "\n",
    "### Modify this ###\n",
    "csv_file_dir = \"../../output/mimic_cxr/nlp_ensemble/corenlp/dcoref\"\n",
    "model_cfg = config.input.source.models.get(\"rb\") # ml -> scoref, rb -> dcoref, fj -> fast_coref_joint\n",
    "model_cfg.dir = csv_file_dir\n",
    "model_cfg.name = \"dcoref\"\n",
    "output_conll_file_pred = os.path.join(output_dir, \"pred_xxx.conll\")\n",
    "\n",
    "check_and_remove_file(output_conll_file_pred)\n",
    "gt_cfg = config.input.ground_truth\n",
    "scorer_cfg = config.scorer\n",
    "spacy_cfg = config.input.spacy\n",
    "\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = gt_dict_allDoc[section_name]\n",
    "    for doc_id in tqdm(doc_list):\n",
    "        pred_file_path = os.path.join(csv_file_dir, section_name, f\"{doc_id}.csv\")\n",
    "        df_pred = pd.read_csv(pred_file_path, index_col=0, na_filter=False)\n",
    "        gt_file_path = os.path.join(source_input_csv_dir, section_name, f\"{doc_id}.csv\")\n",
    "        df_gt = pd.read_csv(gt_file_path, index_col=0, na_filter=False)\n",
    "        spacy_file_path = os.path.join(\"../../output/mimic_cxr/nlp_ensemble/spacy\", section_name, f\"{doc_id}.csv\")\n",
    "        df_spacy = pd.read_csv(spacy_file_path, index_col=0, na_filter=False)\n",
    "\n",
    "        # Some of the i2b2 raw files are utf-8 start with DOM, but we didn't remove the DOM character, thus we fix it here.\n",
    "        df_gt.iloc[0] = df_gt.iloc[0].apply(lambda x: x.replace(\"\\ufeff\", \"\").replace(\"\\xef\\xbb\\xbf\", \"\") if isinstance(x, str) else x)\n",
    "        df_pred.iloc[0] = df_pred.iloc[0].apply(lambda x: x.replace(\"\\ufeff\", \"\").replace(\"\\xef\\xbb\\xbf\", \"\") if isinstance(x, str) else x)\n",
    "        df_spacy.iloc[0] = df_spacy.iloc[0].apply(lambda x: x.replace(\"\\ufeff\", \"\").replace(\"\\xef\\xbb\\xbf\", \"\") if isinstance(x, str) else x)\n",
    "\n",
    "        df_pred = remove_singleton(df_pred, model_cfg.target_column.coref_group_conll)\n",
    "\n",
    "        # Generate conll format predicted files\n",
    "        if model_cfg.align_to_spacy:\n",
    "\n",
    "            # Algin to spacy first, then align spacy to gt\n",
    "            model2spacy_tok_indices, coref_index_appearance_count_dict = align_to_spacy(config, model_cfg, df_spacy, df_pred)\n",
    "\n",
    "            gt_token_list = df_gt.loc[:, gt_cfg.target_column.token_for_alignment].tolist()\n",
    "            spacy_token_list = df_spacy.loc[:, spacy_cfg.target_column.token].tolist()\n",
    "            spacy2gt_tok_indices, _ = align_spacy_to_ground_truth(gt_token_list, spacy_token_list)\n",
    "            sentence_list_pred = convert_non_spacy_token_csv_to_conll_format(config, model_cfg, section_name, doc_id, coref_index_appearance_count_dict, model2spacy_tok_indices,\n",
    "                                                                             spacy2gt_tok_indices, df_pred, df_spacy)\n",
    "        else:\n",
    "            # Directly align to ground-truth\n",
    "            gt_token_list = df_gt.loc[:, gt_cfg.target_column.token_for_alignment].tolist()\n",
    "            spacy_token_list = df_pred.loc[:, model_cfg.target_column.token].tolist()\n",
    "            # Some token has conll label but does not exist in gt, that is what `empty_token_idx_with_conll_label_dict` is used for.\n",
    "            spacy2gt_tok_indices, empty_token_idx_with_conll_label_dict = align_spacy_to_ground_truth(\n",
    "                gt_token_list, spacy_token_list, df_spacy=df_spacy, spacy_cfg=spacy_cfg, df_pred=df_pred, model_cfg=model_cfg)\n",
    "            target_token_index_and_conll_label_dict = find_cloest_index(spacy2gt_tok_indices, empty_token_idx_with_conll_label_dict)\n",
    "            sentence_list_pred = convert_spacy_token_csv_to_conll_format(config, model_cfg, section_name, doc_id, spacy2gt_tok_indices, df_pred, target_token_index_and_conll_label_dict)\n",
    "\n",
    "\n",
    "        # Write conll\n",
    "        from_list_to_conll(output_conll_file_pred, doc_id, section_name, sentence_list_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt: ../../resources/eval/gt_200_noWhich_new.conll\n",
      "pred: ../../resources/eval/pred_xxx.conll\n",
      "Metric: muc\n",
      "mention_recall, mention_precision, mention_f1: 49.57, 59.95, 54.27\n",
      "coref_recall, coref_precision, coref_f1: 38.31, 46.76, 42.12\n",
      "Metric: bcub\n",
      "mention_recall, mention_precision, mention_f1: 49.57, 59.95, 54.27\n",
      "coref_recall, coref_precision, coref_f1: 41.24, 52.13, 46.05\n",
      "Metric: ceafe\n",
      "mention_recall, mention_precision, mention_f1: 49.57, 59.95, 54.27\n",
      "coref_recall, coref_precision, coref_f1: 47.62, 56.98, 51.88\n",
      "Overall F1: 46.68333333333333\n"
     ]
    }
   ],
   "source": [
    "### Modify this ###\n",
    "output_conll_file_gt = os.path.join(output_dir, \"gt_200_noWhich_new.conll\")\n",
    "\n",
    "compute_conll_score(output_conll_file_gt, output_conll_file_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way for testing fast_coref_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modify this ###\n",
    "_input_csv_source_dir = \"../../output/mimic_cxr/nlp_ensemble/temp_for_eval/fast_coref_best\"\n",
    "_output_file_name = \"pred_fjbest.conll\"\n",
    "\n",
    "gt_cfg = config.input.ground_truth\n",
    "scorer_cfg = config.scorer\n",
    "spacy_cfg = config.input.spacy\n",
    "\n",
    "### Modify this with expected output name ###\n",
    "output_conll_file_pred = os.path.join(output_dir, _output_file_name)\n",
    "check_and_remove_file(output_conll_file_pred)\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = gt_dict_allDoc[section_name]\n",
    "    for doc_id in doc_list:\n",
    "        ### Modify this with correct csv file path ###\n",
    "        input_csv_file = os.path.join(_input_csv_source_dir, section_name, f\"{doc_id}.csv\")\n",
    "        df_pred = pd.read_csv(input_csv_file, index_col=0, na_filter=False)\n",
    "        df_pred = remove_singleton(df_pred, \"[fj]coref_group_conll\")\n",
    "        from_csv_to_conll(section_name, doc_id, output_conll_file_pred, df_pred, \"[fj]coref_group_conll\", \"[fj]sentence_group\",\"[fj]token_from_spacy\")\n",
    "\n",
    "### Modify this with correct ground_truth conll file ###\n",
    "output_conll_file_gt = os.path.join(output_dir, \"gt_200_noWhich.conll\")\n",
    "compute_conll_score(output_conll_file_gt, output_conll_file_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: fine-tuned model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../../../git_clone_repos/fast-coref/src\")\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from nlp_ensemble.nlp_menbers import play_fastcoref\n",
    "\n",
    "config = None\n",
    "with initialize(version_base=None, config_path=\"../config\", job_name=\"nlp_ensemble\"):\n",
    "        config = compose(config_name=\"nlp_ensemble\", overrides=[\"+nlp_ensemble@_global_=mimic_cxr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "\n",
    "### Modify ###\n",
    "model_dir = \"../../../../git_clone_repos/fast-coref/models/coref_joint_train_onto_i2b2_301/\"\n",
    "output_conll_file_pred = os.path.join(output_dir, \"pred_model206.conll\")\n",
    "\n",
    "config.fastcoref_joint.model_dir = os.path.join(model_dir,\"best\") if os.path.exists(os.path.join(model_dir,\"best\")) else model_dir\n",
    "model, subword_tokenizer, max_segment_len = play_fastcoref.init_coref_model(config)\n",
    "check_and_remove_file(output_conll_file_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the variable: model_dir and output_conll_file_pred with correct path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using: \",config.fastcoref_joint.model_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model is unstable when the input are slightly different"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the real-world input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inference.tokenize_doc import tokenize_and_segment_doc\n",
    "# from model.utils import action_sequences_to_clusters\n",
    "# from coref_utils.utils import get_mention_to_cluster,filter_clusters\n",
    "# from nlp_ensemble.nlp_menbers.play_fastcoref import inference, resolve_output\n",
    "# from common_utils.nlp_utils import align_byIndex_individually_nestedgruop, align_coref_groups_in_conll_format\n",
    "\n",
    "# spacy_nametyle = config.name_style.spacy.column_name\n",
    "# fastcoref_joint_nametyle = config.name_style.fastcoref_joint.column_name\n",
    "\n",
    "# section_name = \"impression\"\n",
    "# doc_id = \"s51246808\"\n",
    "\n",
    "# spacy_csv_file = os.path.join(\"../../output/mimic_cxr/nlp_ensemble/spacy\", section_name, f\"{doc_id}.csv\")\n",
    "# # Load preprocessed tokens from csv files.\n",
    "# df_base = pd.read_csv(spacy_csv_file, index_col=0)\n",
    "# sent_tok_2d_list: list[list[str]] = format_input_tok_as_realworld(df_base, spacy_nametyle)\n",
    "\n",
    "# # Using longformer tokenizer to generate subtokens and form the input data.\n",
    "# tokenized_doc = tokenize_and_segment_doc(sent_tok_2d_list, subword_tokenizer, max_segment_len=max_segment_len)\n",
    "# print(sent_tok_2d_list)\n",
    "\n",
    "# # Get model output\n",
    "# pred_mentions, mention_scores, gt_actions, pred_actions = inference(model, tokenized_doc)\n",
    "# # Process predicted clusters\n",
    "# raw_predicted_clusters = action_sequences_to_clusters(\n",
    "#     pred_actions, pred_mentions\n",
    "# )\n",
    "# predicted_clusters = filter_clusters(\n",
    "#     raw_predicted_clusters, threshold=2\n",
    "# )\n",
    "# mention_to_predicted = get_mention_to_cluster(predicted_clusters)\n",
    "\n",
    "# for i in predicted_clusters:\n",
    "#     print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equals to the traing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy_nametyle = config.name_style.spacy.column_name\n",
    "# fastcoref_joint_nametyle = config.name_style.fastcoref_joint.column_name\n",
    "\n",
    "# section_name = \"impression\"\n",
    "# doc_id = \"s51246808\"\n",
    "\n",
    "# spacy_csv_file = os.path.join(\"../../output/mimic_cxr/nlp_ensemble/spacy\", section_name, f\"{doc_id}.csv\")\n",
    "\n",
    "# df_base = pd.read_csv(spacy_csv_file, index_col=0)\n",
    "# sent_tok_2d_list: list[list[str]] = format_input_tok_same_as_traingset(df_base, spacy_nametyle)\n",
    "    \n",
    "# print(sent_tok_2d_list)\n",
    "\n",
    "# # Using longformer tokenizer to generate subtokens and form the input data.\n",
    "# tokenized_doc = tokenize_and_segment_doc(sent_tok_2d_list, subword_tokenizer, max_segment_len=max_segment_len)\n",
    "\n",
    "# # Get model output\n",
    "# pred_mentions, mention_scores, gt_actions, pred_actions = inference(model, tokenized_doc)\n",
    "# # Process predicted clusters\n",
    "# raw_predicted_clusters = action_sequences_to_clusters(\n",
    "#     pred_actions, pred_mentions\n",
    "# )\n",
    "# predicted_clusters = filter_clusters(\n",
    "#     raw_predicted_clusters, threshold=2\n",
    "# )\n",
    "# mention_to_predicted = get_mention_to_cluster(predicted_clusters)\n",
    "# for i in predicted_clusters:\n",
    "#     print(i)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.tokenize_doc import tokenize_and_segment_doc\n",
    "from nlp_ensemble.nlp_menbers.play_fastcoref import inference, resolve_output\n",
    "from common_utils.nlp_utils import align_byIndex_individually_nestedgruop, align_coref_groups_in_conll_format\n",
    "\n",
    "spacy_nametyle = config.name_style.spacy.column_name\n",
    "fastcoref_joint_nametyle = config.name_style.fastcoref_joint.column_name\n",
    "\n",
    "# output_conll_file_pred = os.path.join(output_dir, \"pred_joint_best.conll\")\n",
    "# check_and_remove_file(output_conll_file_pred)\n",
    "\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = gt_dict_allDoc[section_name]\n",
    "    for doc_id in tqdm(doc_list):\n",
    "        \n",
    "        spacy_csv_file = os.path.join(\"../../output/mimic_cxr/nlp_ensemble/spacy\", section_name, f\"{doc_id}.csv\")\n",
    "        # Load preprocessed tokens from csv files.\n",
    "        df_base = pd.read_csv(spacy_csv_file, index_col=0)\n",
    "        sent_tok_2d_list, tok_indices_in_spacy = format_input_tok_same_as_traingset(df_base, spacy_nametyle)\n",
    "\n",
    "        # Using longformer tokenizer to generate subtokens and form the input data.\n",
    "        tokenized_doc = tokenize_and_segment_doc(sent_tok_2d_list, subword_tokenizer, max_segment_len=max_segment_len)\n",
    "\n",
    "        # Get model output\n",
    "        pred_mentions, mention_scores, gt_actions, pred_actions = inference(model, tokenized_doc)\n",
    "\n",
    "        # Resolve model output\n",
    "        coref_group_list = resolve_output(tokenized_doc, pred_mentions, pred_actions, ignore_singleton = True)\n",
    "        \n",
    "        # To dataframe\n",
    "        spacy_tok_list = df_base.loc[:, spacy_nametyle.token].to_list()\n",
    "        spacy_sentGroup_list = df_base.loc[:, spacy_nametyle.sentence_group].to_list()\n",
    "        input_tok_list = [tok for sent in sent_tok_2d_list for tok in sent]\n",
    "        \n",
    "        coref_group_aligned_to_input_tok = align_byIndex_individually_nestedgruop(len(input_tok_list), coref_group_list)\n",
    "        coref_group_aligned_to_spacy_tok = align_to_spacy(tok_indices_in_spacy, coref_group_aligned_to_input_tok, input_tok_list, spacy_tok_list)\n",
    "\n",
    "        coref_group_conll_aligned_to_input_tok = align_coref_groups_in_conll_format(len(input_tok_list), coref_group_list)\n",
    "        coref_group_conll_aligned_to_spacy_tok = align_to_spacy(tok_indices_in_spacy, coref_group_conll_aligned_to_input_tok, input_tok_list, spacy_tok_list)\n",
    "        \n",
    "        df_fastcoref_joint = pd.DataFrame(\n",
    "            {\n",
    "                fastcoref_joint_nametyle[\"token_from_spacy\"]: [str(i) for i in spacy_tok_list],\n",
    "                fastcoref_joint_nametyle[\"sentence_group\"]: [int(i) for i in spacy_sentGroup_list],\n",
    "                fastcoref_joint_nametyle[\"coref_group\"]: [str(i) for i in coref_group_aligned_to_spacy_tok],\n",
    "                fastcoref_joint_nametyle[\"coref_group_conll\"]: [str(i) for i in coref_group_conll_aligned_to_spacy_tok],\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Overwrite csv\n",
    "        from_csv_to_conll(section_name, doc_id, output_conll_file_pred, df_fastcoref_joint, \"[fj]coref_group_conll\", \"[fj]sentence_group\",\"[fj]token_from_spacy\")\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval:\n",
    "\n",
    "If gt and pred conll files are existing, we can specify the path and run the following script directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "output_conll_file_gt = os.path.join(output_dir, \"gt_200_noWhich.conll\")\n",
    "# output_conll_file_pred = os.path.join(output_dir, \"pred_model305.conll\")\n",
    "compute_conll_score(output_conll_file_gt, output_conll_file_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "output_conll_file_gt = os.path.join(output_dir, \"gt_100_noWhich.conll\")\n",
    "output_conll_file_pred = os.path.join(output_dir, \"pred_model204.conll\")\n",
    "scorer_path = \"./wrong_conll_scorer_example/coval/scorer.py\"\n",
    "overall_f1 = []\n",
    "command = [\"python\", scorer_path, output_conll_file_gt, output_conll_file_pred]\n",
    "\n",
    "result = subprocess.run(command, capture_output=True, check=True)\n",
    "out = result.stdout.decode('utf-8')\n",
    "err = result.stderr.decode('utf-8')\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('corenlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb6968a69f778f9e728e35b65cd79a0dbef5b20465434381676f63f710dc4a24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
